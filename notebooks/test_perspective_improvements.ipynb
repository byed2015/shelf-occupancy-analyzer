{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerﾃｭas\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Agregar path del proyecto\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from shelf_occupancy.config import load_config\n",
    "from shelf_occupancy.detection import EdgeDetector, LineDetector, ShelfDetector\n",
    "from shelf_occupancy.preprocessing import ImagePreprocessor\n",
    "from shelf_occupancy.utils import load_image\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.rcParams['figure.figsize'] = (20, 12)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"笨 Librerﾃｭas importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df80f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar configuraciﾃｳn\n",
    "config = load_config(\"../config/config.yaml\")\n",
    "\n",
    "# Rutas de imﾃ｡genes de prueba\n",
    "test_images = [\n",
    "    \"../data/raw/SKU110K_fixed/images/test_117.jpg\",\n",
    "    \"../data/raw/SKU110K_fixed/images/test_192.jpg\",\n",
    "    \"../data/raw/SKU110K_fixed/images/test_1006.jpg\"\n",
    "]\n",
    "\n",
    "print(f\"Configuraciﾃｳn cargada\")\n",
    "print(f\"Imﾃ｡genes a probar: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f02881",
   "metadata": {},
   "source": [
    "## Funciﾃｳn de Procesamiento\n",
    "\n",
    "Procesa una imagen con el pipeline completo y extrae estadﾃｭsticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da48a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_with_stats(image_path, adaptive=True):\n",
    "    \"\"\"\n",
    "    Procesa una imagen y retorna estadﾃｭsticas detalladas.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Ruta a la imagen\n",
    "        adaptive: Si True, usa detecciﾃｳn adaptativa de perspectiva\n",
    "    \n",
    "    Returns:\n",
    "        dict con resultados y visualizaciones\n",
    "    \"\"\"\n",
    "    # Cargar imagen\n",
    "    image = load_image(image_path, color_mode=\"BGR\")\n",
    "    \n",
    "    # Preprocesar\n",
    "    preprocessor = ImagePreprocessor(config.preprocessing)\n",
    "    processed = preprocessor.preprocess(image, apply_resize=False, apply_normalize=False)\n",
    "    \n",
    "    # Detectar bordes\n",
    "    edge_detector = EdgeDetector(config.shelf_detection.canny)\n",
    "    edges = edge_detector.detect(processed)\n",
    "    \n",
    "    # Detectar lﾃｭneas\n",
    "    line_detector = LineDetector(config.shelf_detection.hough)\n",
    "    all_lines = line_detector.detect(edges)\n",
    "    \n",
    "    # Filtrar lﾃｭneas (adaptativo o normal)\n",
    "    h_lines = line_detector.filter_by_orientation(\n",
    "        all_lines, \"horizontal\", tolerance=15, adaptive=adaptive\n",
    "    )\n",
    "    v_lines = line_detector.filter_by_orientation(\n",
    "        all_lines, \"vertical\", tolerance=15, adaptive=False\n",
    "    )\n",
    "    \n",
    "    # Detectar ﾃ｡ngulo dominante si es adaptativo\n",
    "    dominant_angle = None\n",
    "    if adaptive and h_lines:\n",
    "        dominant_angle = line_detector.detect_dominant_angle(h_lines)\n",
    "    \n",
    "    # Fusionar lﾃｭneas\n",
    "    if adaptive and dominant_angle is not None:\n",
    "        h_lines = line_detector.merge_similar_lines(h_lines, adaptive_angle=dominant_angle)\n",
    "    else:\n",
    "        h_lines = line_detector.merge_similar_lines(h_lines)\n",
    "    \n",
    "    v_lines = line_detector.merge_similar_lines(v_lines)\n",
    "    \n",
    "    # Detectar anaqueles\n",
    "    shelf_detector = ShelfDetector(config.shelf_detection)\n",
    "    shelves = shelf_detector.detect_from_lines(h_lines, v_lines, processed.shape[:2])\n",
    "    \n",
    "    # Crear visualizaciﾃｳn de lﾃｭneas\n",
    "    lines_img = processed.copy()\n",
    "    for line in h_lines:\n",
    "        cv2.line(lines_img, (int(line.x1), int(line.y1)), \n",
    "                (int(line.x2), int(line.y2)), (0, 255, 0), 2)\n",
    "    for line in v_lines:\n",
    "        cv2.line(lines_img, (int(line.x1), int(line.y1)), \n",
    "                (int(line.x2), int(line.y2)), (255, 0, 0), 2)\n",
    "    \n",
    "    # Crear visualizaciﾃｳn de anaqueles\n",
    "    shelves_img = processed.copy()\n",
    "    for i, shelf in enumerate(shelves):\n",
    "        cv2.rectangle(\n",
    "            shelves_img,\n",
    "            (shelf.x, shelf.y),\n",
    "            (shelf.x + shelf.width, shelf.y + shelf.height),\n",
    "            (0, 255, 255),\n",
    "            3\n",
    "        )\n",
    "        cv2.putText(\n",
    "            shelves_img,\n",
    "            f\"S{i+1}\",\n",
    "            (shelf.x + 10, shelf.y + 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (0, 255, 255),\n",
    "            2\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        'original': image,\n",
    "        'processed': processed,\n",
    "        'lines_img': lines_img,\n",
    "        'shelves_img': shelves_img,\n",
    "        'n_h_lines': len(h_lines),\n",
    "        'n_v_lines': len(v_lines),\n",
    "        'n_shelves': len(shelves),\n",
    "        'dominant_angle': dominant_angle,\n",
    "        'adaptive': adaptive\n",
    "    }\n",
    "\n",
    "print(\"笨 Funciﾃｳn de procesamiento definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43339d7a",
   "metadata": {},
   "source": [
    "## Test 1: test_117.jpg (Frontal)\n",
    "\n",
    "Imagen frontal sin perspectiva significativa. Esperamos resultados similares con/sin modo adaptativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc084ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar test_117.jpg\n",
    "print(\"Procesando test_117.jpg...\")\n",
    "result_117_normal = process_image_with_stats(test_images[0], adaptive=False)\n",
    "result_117_adaptive = process_image_with_stats(test_images[0], adaptive=True)\n",
    "\n",
    "print(\"\\n沒 Resultados test_117.jpg\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Modo Normal:\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {result_117_normal['n_h_lines']}\")\n",
    "print(f\"  - Lﾃｭneas verticales: {result_117_normal['n_v_lines']}\")\n",
    "print(f\"  - Anaqueles detectados: {result_117_normal['n_shelves']}\")\n",
    "print(f\"\\nModo Adaptativo (Perspectiva):\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {result_117_adaptive['n_h_lines']}\")\n",
    "print(f\"  - Lﾃｭneas verticales: {result_117_adaptive['n_v_lines']}\")\n",
    "print(f\"  - Anaqueles detectados: {result_117_adaptive['n_shelves']}\")\n",
    "print(f\"  - ﾃ］gulo dominante: {result_117_adaptive['dominant_angle']:.2f}ﾂｰ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdeca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaciﾃｳn test_117\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "\n",
    "# Fila 1: Modo Normal\n",
    "axes[0, 0].imshow(cv2.cvtColor(result_117_normal['original'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(result_117_normal['lines_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(f'Lﾃｭneas - Normal\\n({result_117_normal[\"n_h_lines\"]}H + {result_117_normal[\"n_v_lines\"]}V)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(cv2.cvtColor(result_117_normal['shelves_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 2].set_title(f'Anaqueles - Normal\\n({result_117_normal[\"n_shelves\"]} detectados)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Fila 2: Modo Adaptativo\n",
    "axes[1, 0].imshow(cv2.cvtColor(result_117_adaptive['original'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(result_117_adaptive['lines_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Lﾃｭneas - Adaptativo\\n({result_117_adaptive[\"n_h_lines\"]}H + {result_117_adaptive[\"n_v_lines\"]}V)\\nﾃ］gulo: {result_117_adaptive[\"dominant_angle\"]:.2f}ﾂｰ', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(cv2.cvtColor(result_117_adaptive['shelves_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title(f'Anaqueles - Adaptativo\\n({result_117_adaptive[\"n_shelves\"]} detectados)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('test_117.jpg - Comparaciﾃｳn Normal vs Adaptativo', fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589322c4",
   "metadata": {},
   "source": [
    "## Test 2: test_192.jpg (Con Perspectiva)\n",
    "\n",
    "Imagen con perspectiva significativa. Esperamos mejoras notables con modo adaptativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar test_192.jpg\n",
    "print(\"Procesando test_192.jpg...\")\n",
    "result_192_normal = process_image_with_stats(test_images[1], adaptive=False)\n",
    "result_192_adaptive = process_image_with_stats(test_images[1], adaptive=True)\n",
    "\n",
    "print(\"\\n沒 Resultados test_192.jpg (CON PERSPECTIVA)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Modo Normal:\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {result_192_normal['n_h_lines']}\")\n",
    "print(f\"  - Lﾃｭneas verticales: {result_192_normal['n_v_lines']}\")\n",
    "print(f\"  - Anaqueles detectados: {result_192_normal['n_shelves']}\")\n",
    "print(f\"\\nModo Adaptativo (Perspectiva):\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {result_192_adaptive['n_h_lines']}\")\n",
    "print(f\"  - Lﾃｭneas verticales: {result_192_adaptive['n_v_lines']}\")\n",
    "print(f\"  - Anaqueles detectados: {result_192_adaptive['n_shelves']}\")\n",
    "print(f\"  - ﾃ］gulo dominante: {result_192_adaptive['dominant_angle']:.2f}ﾂｰ\")\n",
    "\n",
    "# Calcular mejora\n",
    "mejora_lineas = result_192_adaptive['n_h_lines'] - result_192_normal['n_h_lines']\n",
    "mejora_anaqueles = result_192_adaptive['n_shelves'] - result_192_normal['n_shelves']\n",
    "print(f\"\\n笨ｨ Mejora:\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {mejora_lineas:+d} ({mejora_lineas/result_192_normal['n_h_lines']*100:+.1f}%)\")\n",
    "print(f\"  - Anaqueles: {mejora_anaqueles:+d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaciﾃｳn test_192\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "\n",
    "# Fila 1: Modo Normal\n",
    "axes[0, 0].imshow(cv2.cvtColor(result_192_normal['original'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original (CON PERSPECTIVA)', fontsize=14, fontweight='bold', color='red')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(result_192_normal['lines_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(f'Lﾃｭneas - Normal\\n({result_192_normal[\"n_h_lines\"]}H + {result_192_normal[\"n_v_lines\"]}V)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(cv2.cvtColor(result_192_normal['shelves_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 2].set_title(f'Anaqueles - Normal\\n({result_192_normal[\"n_shelves\"]} detectados)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Fila 2: Modo Adaptativo\n",
    "axes[1, 0].imshow(cv2.cvtColor(result_192_adaptive['original'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Original (CON PERSPECTIVA)', fontsize=14, fontweight='bold', color='green')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(result_192_adaptive['lines_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Lﾃｭneas - Adaptativo 笨ｨ\\n({result_192_adaptive[\"n_h_lines\"]}H + {result_192_adaptive[\"n_v_lines\"]}V)\\nﾃ］gulo: {result_192_adaptive[\"dominant_angle\"]:.2f}ﾂｰ', \n",
    "                     fontsize=14, fontweight='bold', color='green')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(cv2.cvtColor(result_192_adaptive['shelves_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title(f'Anaqueles - Adaptativo 笨ｨ\\n({result_192_adaptive[\"n_shelves\"]} detectados)', \n",
    "                     fontsize=14, fontweight='bold', color='green')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('test_192.jpg - Comparaciﾃｳn Normal vs Adaptativo (CON PERSPECTIVA)', \n",
    "             fontsize=18, fontweight='bold', y=0.98, color='red')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12c0b3",
   "metadata": {},
   "source": [
    "## Test 3: test_1006.jpg (Validaciﾃｳn)\n",
    "\n",
    "Imagen aleatoria para validar que las mejoras no rompen casos normales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar test_1006.jpg\n",
    "print(\"Procesando test_1006.jpg...\")\n",
    "result_1006_normal = process_image_with_stats(test_images[2], adaptive=False)\n",
    "result_1006_adaptive = process_image_with_stats(test_images[2], adaptive=True)\n",
    "\n",
    "print(\"\\n沒 Resultados test_1006.jpg\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Modo Normal:\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {result_1006_normal['n_h_lines']}\")\n",
    "print(f\"  - Lﾃｭneas verticales: {result_1006_normal['n_v_lines']}\")\n",
    "print(f\"  - Anaqueles detectados: {result_1006_normal['n_shelves']}\")\n",
    "print(f\"\\nModo Adaptativo (Perspectiva):\")\n",
    "print(f\"  - Lﾃｭneas horizontales: {result_1006_adaptive['n_h_lines']}\")\n",
    "print(f\"  - Lﾃｭneas verticales: {result_1006_adaptive['n_v_lines']}\")\n",
    "print(f\"  - Anaqueles detectados: {result_1006_adaptive['n_shelves']}\")\n",
    "print(f\"  - ﾃ］gulo dominante: {result_1006_adaptive['dominant_angle']:.2f}ﾂｰ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ee6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaciﾃｳn test_1006\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "\n",
    "# Fila 1: Modo Normal\n",
    "axes[0, 0].imshow(cv2.cvtColor(result_1006_normal['original'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(result_1006_normal['lines_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(f'Lﾃｭneas - Normal\\n({result_1006_normal[\"n_h_lines\"]}H + {result_1006_normal[\"n_v_lines\"]}V)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(cv2.cvtColor(result_1006_normal['shelves_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[0, 2].set_title(f'Anaqueles - Normal\\n({result_1006_normal[\"n_shelves\"]} detectados)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Fila 2: Modo Adaptativo\n",
    "axes[1, 0].imshow(cv2.cvtColor(result_1006_adaptive['original'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(result_1006_adaptive['lines_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Lﾃｭneas - Adaptativo\\n({result_1006_adaptive[\"n_h_lines\"]}H + {result_1006_adaptive[\"n_v_lines\"]}V)\\nﾃ］gulo: {result_1006_adaptive[\"dominant_angle\"]:.2f}ﾂｰ', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(cv2.cvtColor(result_1006_adaptive['shelves_img'], cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title(f'Anaqueles - Adaptativo\\n({result_1006_adaptive[\"n_shelves\"]} detectados)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('test_1006.jpg - Comparaciﾃｳn Normal vs Adaptativo', fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885d293",
   "metadata": {},
   "source": [
    "## Resumen de Resultados\n",
    "\n",
    "Comparaciﾃｳn cuantitativa de las 3 imﾃ｡genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear tabla comparativa\n",
    "results_summary = pd.DataFrame({\n",
    "    'Imagen': ['test_117', 'test_117', 'test_192', 'test_192', 'test_1006', 'test_1006'],\n",
    "    'Modo': ['Normal', 'Adaptativo', 'Normal', 'Adaptativo', 'Normal', 'Adaptativo'],\n",
    "    'Lﾃｭneas H': [\n",
    "        result_117_normal['n_h_lines'], result_117_adaptive['n_h_lines'],\n",
    "        result_192_normal['n_h_lines'], result_192_adaptive['n_h_lines'],\n",
    "        result_1006_normal['n_h_lines'], result_1006_adaptive['n_h_lines']\n",
    "    ],\n",
    "    'Lﾃｭneas V': [\n",
    "        result_117_normal['n_v_lines'], result_117_adaptive['n_v_lines'],\n",
    "        result_192_normal['n_v_lines'], result_192_adaptive['n_v_lines'],\n",
    "        result_1006_normal['n_v_lines'], result_1006_adaptive['n_v_lines']\n",
    "    ],\n",
    "    'Anaqueles': [\n",
    "        result_117_normal['n_shelves'], result_117_adaptive['n_shelves'],\n",
    "        result_192_normal['n_shelves'], result_192_adaptive['n_shelves'],\n",
    "        result_1006_normal['n_shelves'], result_1006_adaptive['n_shelves']\n",
    "    ],\n",
    "    'ﾃ］gulo (ﾂｰ)': [\n",
    "        '-', f\"{result_117_adaptive['dominant_angle']:.2f}\",\n",
    "        '-', f\"{result_192_adaptive['dominant_angle']:.2f}\",\n",
    "        '-', f\"{result_1006_adaptive['dominant_angle']:.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n沒 RESUMEN DE RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "print(results_summary.to_string(index=False))\n",
    "\n",
    "# Mostrar tabla con estilo\n",
    "display(results_summary.style.set_properties(**{'text-align': 'center'}).set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('text-align', 'center'), ('font-weight', 'bold')]}]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0010b",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "### Mejoras Observadas:\n",
    "\n",
    "1. **test_117.jpg (Frontal)**: \n",
    "   - Modo adaptativo mantiene resultados similares 笨\n",
    "   - ﾃ］gulo dominante cercano a 0ﾂｰ (sin perspectiva)\n",
    "   - No hay degradaciﾃｳn en imﾃ｡genes frontales\n",
    "\n",
    "2. **test_192.jpg (Con Perspectiva)**:\n",
    "   - Modo adaptativo detecta mﾃ｡s lﾃｭneas horizontales inclinadas 笨\n",
    "   - ﾃ］gulo dominante significativo (>5ﾂｰ)\n",
    "   - Mejor detecciﾃｳn de anaqueles\n",
    "\n",
    "3. **test_1006.jpg (Validaciﾃｳn)**:\n",
    "   - Modo adaptativo funciona correctamente 笨\n",
    "   - Resultados consistentes\n",
    "\n",
    "### Recomendaciﾃｳn:\n",
    "\n",
    "笨 **Usar modo adaptativo (`adaptive=True`) por defecto** - Maneja tanto imﾃ｡genes frontales como con perspectiva sin degradar resultados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a738ca6",
   "metadata": {},
   "source": [
    "# Test 01: Descarga y Preprocesamiento de Im√°genes\n",
    "\n",
    "Este notebook valida:\n",
    "1. Descarga del dataset SKU-110K\n",
    "2. Preprocesamiento de im√°genes\n",
    "3. Visualizaci√≥n de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from loguru import logger\n",
    "\n",
    "# Configurar logging\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec32db",
   "metadata": {},
   "source": [
    "## 1. Importar m√≥dulos del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00743a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shelf_occupancy.config import load_config\n",
    "from shelf_occupancy.utils import load_image, save_image\n",
    "from shelf_occupancy.preprocessing import ImagePreprocessor\n",
    "\n",
    "# Cargar configuraci√≥n\n",
    "config = load_config()\n",
    "print(\"‚úÖ Configuraci√≥n cargada\")\n",
    "print(f\"   - Target size: {config.preprocessing.target_size}\")\n",
    "print(f\"   - CLAHE clip limit: {config.preprocessing.clahe.clip_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2466ba61",
   "metadata": {},
   "source": [
    "## 2. Descargar dataset (si es necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: Por ahora vamos a usar im√°genes de ejemplo\n",
    "# Si quieres descargar el dataset completo, ejecuta:\n",
    "# !uv run python -m shelf_occupancy.data.download_dataset --n-samples 10\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "raw_dir = data_dir / \"raw\" / \"sample\"\n",
    "processed_dir = data_dir / \"processed\"\n",
    "results_dir = data_dir / \"results\"\n",
    "\n",
    "# Crear directorios\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Directorios creados:\")\n",
    "print(f\"   - Raw: {raw_dir}\")\n",
    "print(f\"   - Processed: {processed_dir}\")\n",
    "print(f\"   - Results: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd0a90",
   "metadata": {},
   "source": [
    "## 3. Crear imagen de prueba\n",
    "\n",
    "Como el dataset SKU-110K es pesado, vamos a crear una imagen sint√©tica para probar el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a93fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def create_synthetic_shelf_image(width=800, height=600):\n",
    "    \"\"\"Crea una imagen sint√©tica de anaquel para pruebas.\"\"\"\n",
    "    # Crear imagen base\n",
    "    img = np.ones((height, width, 3), dtype=np.uint8) * 200\n",
    "    \n",
    "    # Agregar ruido\n",
    "    noise = np.random.randint(-30, 30, (height, width, 3), dtype=np.int16)\n",
    "    img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Dibujar l√≠neas horizontales (anaqueles)\n",
    "    shelf_heights = [100, 250, 400, 550]\n",
    "    for y in shelf_heights:\n",
    "        cv2.line(img, (0, y), (width, y), (50, 50, 50), 3)\n",
    "    \n",
    "    # Dibujar l√≠neas verticales (divisiones)\n",
    "    for x in range(0, width, 150):\n",
    "        cv2.line(img, (x, 0), (x, height), (60, 60, 60), 2)\n",
    "    \n",
    "    # Simular productos (rect√°ngulos)\n",
    "    colors = [(180, 100, 100), (100, 180, 100), (100, 100, 180), (180, 180, 100)]\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for shelf_y in shelf_heights[:-1]:\n",
    "        for i in range(5):\n",
    "            x = np.random.randint(10, width - 80)\n",
    "            y = shelf_y + np.random.randint(10, 100)\n",
    "            w = np.random.randint(40, 80)\n",
    "            h = np.random.randint(60, 120)\n",
    "            color = colors[np.random.randint(0, len(colors))]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, -1)\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 0), 2)\n",
    "    \n",
    "    # Agregar variaci√≥n de iluminaci√≥n\n",
    "    overlay = np.zeros_like(img)\n",
    "    cv2.circle(overlay, (width // 3, height // 3), 400, (255, 255, 255), -1)\n",
    "    img = cv2.addWeighted(img, 0.7, overlay, 0.3, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Crear y guardar imagen sint√©tica\n",
    "test_img = create_synthetic_shelf_image()\n",
    "test_img_path = raw_dir / \"test_shelf.jpg\"\n",
    "save_image(test_img, test_img_path)\n",
    "\n",
    "print(f\"‚úÖ Imagen de prueba creada: {test_img_path}\")\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Imagen Sint√©tica de Anaquel\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d6a5b",
   "metadata": {},
   "source": [
    "## 4. Probar preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca25a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar imagen\n",
    "image = load_image(test_img_path, color_mode=\"BGR\")\n",
    "print(f\"Imagen cargada: {image.shape}, dtype: {image.dtype}\")\n",
    "\n",
    "# Crear preprocesador\n",
    "preprocessor = ImagePreprocessor(config.preprocessing)\n",
    "\n",
    "# Aplicar cada paso individualmente para visualizaci√≥n\n",
    "img_clahe = preprocessor.apply_clahe(image.copy())\n",
    "img_filtered = preprocessor.apply_bilateral_filter(img_clahe.copy())\n",
    "img_resized = preprocessor.resize(img_filtered.copy())\n",
    "\n",
    "print(f\"‚úÖ Preprocesamiento completado\")\n",
    "print(f\"   - CLAHE: {img_clahe.shape}\")\n",
    "print(f\"   - Filtrado: {img_filtered.shape}\")\n",
    "print(f\"   - Redimensionado: {img_resized.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23499fe6",
   "metadata": {},
   "source": [
    "## 5. Visualizar comparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73136b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# CLAHE\n",
    "axes[0, 1].imshow(cv2.cvtColor(img_clahe, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('CLAHE (Correcci√≥n de Iluminaci√≥n)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Filtrado bilateral\n",
    "axes[1, 0].imshow(cv2.cvtColor(img_filtered, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Filtrado Bilateral (Reducci√≥n de Ruido)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Redimensionado\n",
    "axes[1, 1].imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Redimensionado {img_resized.shape[:2][::-1]}', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'preprocessing_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Comparaci√≥n guardada en: {results_dir / 'preprocessing_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70304311",
   "metadata": {},
   "source": [
    "## 6. Guardar imagen preprocesada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b67b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar versi√≥n procesada\n",
    "processed_path = processed_dir / \"test_shelf_processed.jpg\"\n",
    "save_image(img_resized, processed_path)\n",
    "\n",
    "print(f\"‚úÖ Imagen procesada guardada: {processed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135db3c",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_comparison(img1, img2, title1=\"Original\", title2=\"Procesada\"):\n",
    "    \"\"\"Compara histogramas de dos im√°genes.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    \n",
    "    colors = ('b', 'g', 'r')\n",
    "    titles = ['Blue', 'Green', 'Red']\n",
    "    \n",
    "    for i, (color, title) in enumerate(zip(colors, titles)):\n",
    "        # Histograma imagen 1\n",
    "        hist1 = cv2.calcHist([img1], [i], None, [256], [0, 256])\n",
    "        axes[0, i].plot(hist1, color=color)\n",
    "        axes[0, i].set_title(f'{title1} - {title}', fontweight='bold')\n",
    "        axes[0, i].set_xlim([0, 256])\n",
    "        axes[0, i].grid(alpha=0.3)\n",
    "        \n",
    "        # Histograma imagen 2\n",
    "        hist2 = cv2.calcHist([img2], [i], None, [256], [0, 256])\n",
    "        axes[1, i].plot(hist2, color=color)\n",
    "        axes[1, i].set_title(f'{title2} - {title}', fontweight='bold')\n",
    "        axes[1, i].set_xlim([0, 256])\n",
    "        axes[1, i].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_histogram_comparison(image, img_clahe, \"Original\", \"CLAHE\")\n",
    "plt.savefig(results_dir / 'histogram_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Comparaci√≥n de histogramas completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd7506",
   "metadata": {},
   "source": [
    "## ‚úÖ Resumen\n",
    "\n",
    "En este notebook hemos validado:\n",
    "\n",
    "1. ‚úÖ Carga de configuraci√≥n desde YAML\n",
    "2. ‚úÖ Creaci√≥n de imagen sint√©tica de anaquel\n",
    "3. ‚úÖ Preprocesamiento con CLAHE (correcci√≥n de iluminaci√≥n)\n",
    "4. ‚úÖ Filtrado bilateral (reducci√≥n de ruido)\n",
    "5. ‚úÖ Redimensionamiento de im√°genes\n",
    "6. ‚úÖ Visualizaci√≥n de resultados\n",
    "7. ‚úÖ An√°lisis de histogramas\n",
    "\n",
    "**Pr√≥ximos pasos:**\n",
    "- Implementar detecci√≥n de bordes y l√≠neas\n",
    "- Integrar Depth-Anything-V2 para estimaci√≥n de profundidad\n",
    "- Desarrollar an√°lisis de ocupaci√≥n por cuadr√≠culas"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

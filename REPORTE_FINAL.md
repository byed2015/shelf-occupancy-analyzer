# Sistema de AnÃ¡lisis AutomÃ¡tico de OcupaciÃ³n de Anaqueles mediante VisiÃ³n Computacional y Profundidad

**MaestrÃ­a en Inteligencia Artificial y Ciencia de Datos**  
**Proyecto Final â€“ VisiÃ³n Computacional**

---

**Trabajo presentado por:**
- EDGAR ALBERTO MORALES GUTIÃ‰RREZ
- GUSTAVO ALBERTO GÃ“MEZ ROJAS

---

## Tabla de Contenidos

- [Sistema de AnÃ¡lisis AutomÃ¡tico de OcupaciÃ³n de Anaqueles mediante VisiÃ³n Computacional y Profundidad](#sistema-de-anÃ¡lisis-automÃ¡tico-de-ocupaciÃ³n-de-anaqueles-mediante-visiÃ³n-computacional-y-profundidad)
  - [Tabla de Contenidos](#tabla-de-contenidos)
  - [1. IntroducciÃ³n y fundamentaciÃ³n](#1-introducciÃ³n-y-fundamentaciÃ³n)
    - [1.1. Planteamiento del Problema](#11-planteamiento-del-problema)
    - [1.2. Relevancia en el campo de la visiÃ³n computacional](#12-relevancia-en-el-campo-de-la-visiÃ³n-computacional)
    - [1.3. Objetivo General](#13-objetivo-general)
    - [1.4. Objetivos especÃ­ficos](#14-objetivos-especÃ­ficos)
  - [2. MetodologÃ­a detallada](#2-metodologÃ­a-detallada)
    - [2.1. Estructura del pipeline](#21-estructura-del-pipeline)
    - [2.2. TÃ©cnicas de visiÃ³n computacional utilizadas](#22-tÃ©cnicas-de-visiÃ³n-computacional-utilizadas)
      - [1. Preprocesamiento](#1-preprocesamiento)
      - [2. DetecciÃ³n de bordes](#2-detecciÃ³n-de-bordes)
      - [3. DetecciÃ³n de lÃ­neas](#3-detecciÃ³n-de-lÃ­neas)
      - [4. SegmentaciÃ³n en cuadrilÃ¡teros](#4-segmentaciÃ³n-en-cuadrilÃ¡teros)
      - [5. EstimaciÃ³n de profundidad](#5-estimaciÃ³n-de-profundidad)
      - [6. AnÃ¡lisis de ocupaciÃ³n](#6-anÃ¡lisis-de-ocupaciÃ³n)
    - [2.3. Datos, condiciones de captura y hardware](#23-datos-condiciones-de-captura-y-hardware)
      - [Dataset principal](#dataset-principal)
      - [Estructura de datos en el repositorio](#estructura-de-datos-en-el-repositorio)
      - [Condiciones de captura previstas](#condiciones-de-captura-previstas)
      - [Hardware utilizado (ejemplo sugerido)](#hardware-utilizado-ejemplo-sugerido)
    - [2.4. ParÃ¡metros y criterios de ajuste](#24-parÃ¡metros-y-criterios-de-ajuste)
  - [3. ImplementaciÃ³n y explicaciÃ³n tÃ©cnica](#3-implementaciÃ³n-y-explicaciÃ³n-tÃ©cnica)
    - [3.1. OrganizaciÃ³n del cÃ³digo](#31-organizaciÃ³n-del-cÃ³digo)
    - [3.2. Flujo de ejecuciÃ³n principal](#32-flujo-de-ejecuciÃ³n-principal)
    - [3.3. LibrerÃ­as utilizadas](#33-librerÃ­as-utilizadas)
    - [3.4. Robustez del sistema](#34-robustez-del-sistema)
  - [4. Resultados y anÃ¡lisis](#4-resultados-y-anÃ¡lisis)
    - [4.1. Evidencia visual](#41-evidencia-visual)
    - [4.2. Resultados cuantitativos (ejemplos)](#42-resultados-cuantitativos-ejemplos)
      - [Imagen test\_192.jpg](#imagen-test_192jpg)
      - [Imagen test\_179.jpg](#imagen-test_179jpg)
    - [4.3. AnÃ¡lisis crÃ­tico](#43-anÃ¡lisis-crÃ­tico)
    - [4.4. Limitaciones y posibles errores](#44-limitaciones-y-posibles-errores)
    - [4.5. Propuestas de mejora y trabajo futuro](#45-propuestas-de-mejora-y-trabajo-futuro)
  - [5. InnovaciÃ³n y complejidad del proyecto](#5-innovaciÃ³n-y-complejidad-del-proyecto)
    - [Elementos innovadores y de alta complejidad tÃ©cnica:](#elementos-innovadores-y-de-alta-complejidad-tÃ©cnica)
  - [6. Conclusiones](#6-conclusiones)
    - [Resumen de logros:](#resumen-de-logros)
  - [7. Referencias](#7-referencias)

---

## 1. IntroducciÃ³n y fundamentaciÃ³n

### 1.1. Planteamiento del Problema

En el entorno actual del comercio minorista, la correcta gestiÃ³n de anaqueles es un factor determinante para la competitividad. Un anaquel vacÃ­o implica ventas perdidas, afecta la percepciÃ³n del cliente sobre la tienda y, en escenarios acumulados, puede distorsionar el anÃ¡lisis de la demanda real. Tradicionalmente, el monitoreo de anaqueles se realiza mediante recorridos manuales, donde el personal de piso identifica visualmente huecos y faltantes. Este enfoque es costoso, lento, subjetivo y difÃ­cil de escalar a cadenas con cientos de sucursales.

El proyecto "Shelf Occupancy Analyzer" surge para responder a este problema desde la visiÃ³n computacional, proponiendo un sistema capaz de estimar automÃ¡ticamente la ocupaciÃ³n de los anaqueles a partir de una sola imagen. Para ello, se combinan tÃ©cnicas clÃ¡sicas (detecciÃ³n de bordes y lÃ­neas, segmentaciÃ³n geomÃ©trica) con modelos modernos de aprendizaje profundo para estimaciÃ³n de profundidad monocular. La idea central es que la profundidad aporta una dimensiÃ³n adicional que permite diferenciar mejor entre fondo del anaquel y producto exhibido, incluso cuando los colores son similares.

El sistema no solo busca generar una mÃ©trica numÃ©rica de ocupaciÃ³n, sino tambiÃ©n producir visualizaciones claras que puedan ser interpretadas por usuarios no tÃ©cnicos, como gerentes de tienda o personal de reposiciÃ³n. De esta forma, el proyecto se sitÃºa en la intersecciÃ³n entre la teorÃ­a de la visiÃ³n computacional y una necesidad operativa real, con potencial de uso en analÃ­tica de retail, administraciÃ³n de inventarios y sistemas de alerta temprana ante desabasto.

### 1.2. Relevancia en el campo de la visiÃ³n computacional

El problema es representativo de diversos temas centrales de la visiÃ³n computacional:

1. **DetecciÃ³n de bordes y lÃ­neas (Canny + Hough)**: extracciÃ³n de la estructura geomÃ©trica dominante en la escena.
2. **SegmentaciÃ³n geomÃ©trica basada en cuadrilÃ¡teros**: particiÃ³n de la escena en regiones de interÃ©s (anaqueles) respetando la perspectiva.
3. **EstimaciÃ³n de profundidad monocular con redes neuronales profundas**: aproximaciÃ³n moderna relacionada con la visiÃ³n estÃ©reo, pero utilizando una sola imagen.
4. **AnÃ¡lisis estadÃ­stico de mapas de profundidad**: uso de medianas, percentiles y varianza para inferir ocupaciÃ³n y distinguir fondo vs. producto.

Con ello, el proyecto integra al menos dos unidades temÃ¡ticas tÃ­picas del curso: procesamiento y detecciÃ³n de caracterÃ­sticas, segmentaciÃ³n y anÃ¡lisis de profundidad.

### 1.3. Objetivo General

Desarrollar e implementar un sistema profesional de anÃ¡lisis de ocupaciÃ³n de anaqueles que, a partir de una imagen, detecte automÃ¡ticamente los anaqueles, estime su nivel de ocupaciÃ³n utilizando mapas de profundidad y genere visualizaciones y mÃ©tricas cuantitativas Ãºtiles para operaciÃ³n y analÃ­tica.

### 1.4. Objetivos especÃ­ficos

1. DiseÃ±ar un pipeline modular de visiÃ³n computacional que abarque preprocesamiento, detecciÃ³n de estructura, estimaciÃ³n de profundidad y anÃ¡lisis de ocupaciÃ³n.
2. Implementar detecciÃ³n robusta de lÃ­neas horizontales y verticales mediante Canny + Transformada de Hough y clustering, para obtener cuadrilÃ¡teros correspondientes a anaqueles.
3. Integrar el modelo de profundidad monocular Depth-Anything-V2-Small para generar mapas de profundidad sobre imÃ¡genes de anaqueles.
4. Definir una mÃ©trica de ocupaciÃ³n basada en la mediana de profundidad dentro de cada cuadrilÃ¡tero, asignando un porcentaje de llenado a cada anaquel.
5. Evaluar la robustez del sistema ante variaciones razonables de perspectiva, iluminaciÃ³n y ruido, utilizando imÃ¡genes del dataset SKU-110K y muestras adicionales.

---

## 2. MetodologÃ­a detallada

La metodologÃ­a se estructura como un pipeline de procesamiento de imagen en siete pasos principales, diseÃ±ados para ser modulares y trazables. En primer lugar, se recibe una imagen del anaquel, capturada en condiciones tÃ­picas de una tienda (iluminaciÃ³n artificial y perspectiva moderadamente inclinada). A partir de esta entrada, se aplica un preprocesamiento ligero que incluye suavizado mediante desenfoque Gaussiano. Este paso reduce el ruido de alta frecuencia sin destruir los bordes relevantes que serÃ¡n utilizados mÃ¡s adelante.

Posteriormente, se ejecuta el detector de bordes Canny, cuyos umbrales no se fijan de forma estÃ¡tica, sino que se calculan en funciÃ³n de la mediana de intensidades de la imagen. Esto permite adaptar la sensibilidad del detector a escenas mÃ¡s claras u oscuras. Con el mapa de bordes, se utiliza la Transformada de Hough para localizar lÃ­neas rectas prominentes. Mediante filtrado angular se separan las lÃ­neas horizontales y verticales, y con tÃ©cnicas de clustering se agrupan lÃ­neas similares, para obtener una representaciÃ³n mÃ¡s estable de la estructura del anaquel.

Con las familias de lÃ­neas resultantes se construyen cuadrilÃ¡teros que representan los anaqueles individuales, respetando la perspectiva de la escena. En paralelo, se envÃ­a la imagen al modelo de profundidad monocular, que genera un mapa de profundidad continuo sobre toda la imagen. Finalmente, para cada cuadrilÃ¡tero se extrae la porciÃ³n correspondiente del mapa de profundidad y se calcula una estadÃ­stica robusta (mediana), que se transforma en un porcentaje de ocupaciÃ³n. El pipeline concluye con la generaciÃ³n de visualizaciones y un reporte con los porcentajes por anaquel e imagen completa.

### 2.1. Estructura del pipeline

El sistema sigue un pipeline de 7 pasos optimizados (v1.3.1):

1. **Imagen original**
2. **Preprocesamiento** (suavizado ligero)
3. **DetecciÃ³n de bordes** (Canny con auto-umbrales basados en la mediana de la imagen)
4. **DetecciÃ³n y fusiÃ³n de lÃ­neas** (Transformada de Hough + clustering DBSCAN)
5. **SegmentaciÃ³n en cuadrilÃ¡teros inclinados** (anaqueles)
6. **EstimaciÃ³n de profundidad** mediante Depth-Anything-V2
7. **AnÃ¡lisis de ocupaciÃ³n** con mediana directa y visualizaciÃ³n con cuadrilÃ¡teros coloreados

Este pipeline se implementa en el script `visualize_pipeline.py`, que orquesta los mÃ³dulos de `src/shelf_occupancy/` y genera una imagen concatenada con los principales pasos y un reporte de mÃ©tricas.

### 2.2. TÃ©cnicas de visiÃ³n computacional utilizadas

#### 1. Preprocesamiento

- **Desenfoque Gaussiano 5Ã—5 (Ïƒ=1.0)** para reducir ruido preservando bordes.
- *(Versiones anteriores incluÃ­an CLAHE y filtro bilateral, posteriormente simplificados para mejorar velocidad)*

#### 2. DetecciÃ³n de bordes

- **Canny** con umbrales adaptativos calculados a partir la mediana de intensidades de la imagen, mejorando robustez frente a cambios de iluminaciÃ³n.

#### 3. DetecciÃ³n de lÃ­neas

- **Transformada de Hough** (HoughLines / HoughLinesP) para obtener lÃ­neas candidatas.
- **Filtrado "ABSOLUTO"** por orientaciÃ³n:
  - Horizontales: ~0Â°/180Â° Â±20Â°
  - Verticales: ~90Â° Â±20Â°
- **Clustering con DBSCAN** y fusiÃ³n de lÃ­neas similares por Ã¡ngulo y distancia.

#### 4. SegmentaciÃ³n en cuadrilÃ¡teros

- A partir de las familias de lÃ­neas horizontales y verticales, el mÃ³dulo `ShelfDetector` genera cuadrilÃ¡teros que siguen la geometrÃ­a real de cada anaquel, sin corregir la perspectiva global.

#### 5. EstimaciÃ³n de profundidad

- Uso del modelo **Depth-Anything-V2-Small-hf**, cargado vÃ­a PyTorch/HuggingFace, para producir un mapa de profundidad normalizado (minâ€“max) de la escena completa.

#### 6. AnÃ¡lisis de ocupaciÃ³n

- **MÃ©todo de "mediana directa"**: se crea una mÃ¡scara binaria del cuadrilÃ¡tero, se extraen los valores de profundidad, se calcula la mediana, y se define la ocupaciÃ³n como:
  
  ```
  OcupaciÃ³n = (1 - mediana) Ã— 100%
  ```

### 2.3. Datos, condiciones de captura y hardware

#### Dataset principal
- **SKU-110K**: un conjunto de imÃ¡genes de anaqueles minoristas con miles de productos anotados.

#### Estructura de datos en el repositorio
- `data/raw/SKU110K_fixed/images/`: contiene imÃ¡genes de prueba
- `data/results/`: almacena resultados, reportes y visualizaciones

#### Condiciones de captura previstas
- ImÃ¡genes tomadas en pasillos de supermercado
- Variaciones moderadas de perspectiva
- IluminaciÃ³n artificial
- Presencia de ruido visual (personas, carteles)

#### Hardware utilizado (ejemplo sugerido)
- **CPU**: al menos 4 nÃºcleos, 8 GB de RAM
- **GPU** (opcional): para acelerar la inferencia de profundidad
- **Sistema operativo**: Linux/Windows con Python 3.10+

### 2.4. ParÃ¡metros y criterios de ajuste

Algunos parÃ¡metros clave definidos en `config/config.yaml` incluyen:

- `shelf_detection.canny.low_threshold` / `high_threshold`: sensibilidad de bordes
- `shelf_detection.hough.threshold`: sensibilidad de la Transformada de Hough
- `depth_estimation.model_name` y `device`: elecciÃ³n de modelo de profundidad y uso de CPU/GPU
- `occupancy_analysis.thresholds.min_occupancy`: umbral mÃ­nimo para considerar un anaquel "ocupado" o "vacÃ­o"

Estos parÃ¡metros se ajustan empÃ­ricamente observando tanto el mapa de bordes y lÃ­neas detectadas como los porcentajes de ocupaciÃ³n resultantes sobre imÃ¡genes de validaciÃ³n.

---

## 3. ImplementaciÃ³n y explicaciÃ³n tÃ©cnica

La implementaciÃ³n se basa en una arquitectura modular escrita en Python, con una organizaciÃ³n clara por capas dentro del directorio `src/shelf_occupancy`. En la capa de entrada se encuentran los scripts principales, como `visualize_pipeline.py` y `process_all_images.py`, que sirven como puntos de acceso al sistema. Estos scripts leen la configuraciÃ³n desde un archivo `config.yaml`, cargan las imÃ¡genes desde el directorio de datos y orquestan la ejecuciÃ³n de los mÃ³dulos internos.

En la capa de procesamiento, el mÃ³dulo de preprocesamiento encapsula operaciones como lectura de imagen, conversiÃ³n de espacio de color, redimensionamiento y suavizado. La detecciÃ³n de bordes y lÃ­neas se implementa utilizando OpenCV, con funciones especÃ­ficas para Canny y Hough, mientras que el filtrado y clustering de lÃ­neas aprovecha estructuras de datos de NumPy y, en algunos casos, algoritmos de agrupamiento como DBSCAN. El diseÃ±o busca mantener las funciones puras y fÃ¡ciles de probar, evitando lÃ³gica mezclada entre lectura de archivos y operaciones matemÃ¡ticas.

La capa de profundidad integra un modelo preentrenado como Depth-Anything-V2, cargado mediante PyTorch. Se realiza la normalizaciÃ³n adecuada de la imagen, se pasa por la red neuronal y el mapa de profundidad resultante se reescala a las dimensiones originales. La capa de anÃ¡lisis define cÃ³mo se construye la mÃ¡scara del cuadrilÃ¡tero, cÃ³mo se extraen los valores dentro de Ã©l y cÃ³mo se calcula la mediana de profundidad. Finalmente, el mÃ³dulo de visualizaciÃ³n genera imÃ¡genes compuestas con los distintos pasos del pipeline, dibuja los cuadrilÃ¡teros coloreados segÃºn la ocupaciÃ³n y, si se requiere, guarda mÃ©tricas en archivos de texto o CSV para anÃ¡lisis posterior.

### 3.1. OrganizaciÃ³n del cÃ³digo

El proyecto sigue una arquitectura modular organizada en capas:

```
shelf-occupancy-analyzer/
â”œâ”€â”€ visualize_pipeline.py          # Script principal de alto nivel
â”œâ”€â”€ process_all_images.py          # Procesamiento batch
â”‚
â”œâ”€â”€ src/shelf_occupancy/            # LÃ³gica de negocio
â”‚   â”œâ”€â”€ preprocessing/              # image_processor.py
â”‚   â”œâ”€â”€ detection/                  # edges.py, lines.py, shelves.py
â”‚   â”œâ”€â”€ depth/                      # estimator.py
â”‚   â”œâ”€â”€ analysis/                   # grid_analysis.py
â”‚   â”œâ”€â”€ visualization/              # overlay.py
â”‚   â””â”€â”€ utils/                      # geometry.py, image_io.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n centralizada
â”‚
â””â”€â”€ notebooks/                      # Notebooks exploratorios
```

Esta estructura facilita el mantenimiento, la extensiÃ³n del sistema y la integraciÃ³n en pipelines MLOps.

### 3.2. Flujo de ejecuciÃ³n principal

Para una imagen individual, el flujo estÃ¡ndar es:

1. Cargar configuraciÃ³n (`load_config`) y la imagen (`load_image`)
2. Aplicar preprocesamiento (suavizado, opcionalmente CLAHE/filtro bilateral)
3. Calcular bordes con Canny
4. Detectar lÃ­neas con Hough y filtrarlas segÃºn orientaciÃ³n
5. Ejecutar `ShelfDetector` para generar los cuadrilÃ¡teros de anaqueles
6. Estimar el mapa de profundidad usando `DepthEstimator`
7. Para cada cuadrilÃ¡tero:
   - Construir mÃ¡scara
   - Extraer profundidades
   - Calcular mediana y porcentaje de ocupaciÃ³n
8. Generar visualizaciones (overlay de cuadrilÃ¡teros coloreados, imagen con los 7 pasos del pipeline) y reporte de mÃ©tricas en texto/CSV

### 3.3. LibrerÃ­as utilizadas

1. **OpenCV**: lectura/escritura de imÃ¡genes, desenfoque Gaussiano, Canny, Hough, operaciones geomÃ©tricas y morfolÃ³gicas
2. **NumPy**: operaciones numÃ©ricas (mediana, percentiles, mÃ¡scaras)
3. **PyTorch + Transformers (HuggingFace)**: carga e inferencia del modelo Depth-Anything-V2 para estimaciÃ³n de profundidad
4. **scikit-learn (DBSCAN)**: clustering de lÃ­neas y agrupaciÃ³n de estructuras
5. **loguru**: logging estructurado

### 3.4. Robustez del sistema

1. **Umbrales de Canny adaptativos** a la mediana de intensidades, lo que mejora el desempeÃ±o en diferentes condiciones de iluminaciÃ³n
2. **Filtrado absoluto de lÃ­neas** horizontales/verticales, que evita que el sistema se "incline" siguiendo el Ã¡ngulo dominante y pierda la estructura del anaquel
3. **Arquitectura de cuadrilÃ¡teros** que mantiene la imagen original sin correcciÃ³n de perspectiva global; solo se realiza warp local por anaquel cuando es necesario
4. **Uso de la mediana de profundidad** (estadÃ­stica robusta frente a outliers) para calcular ocupaciÃ³n

---

## 4. Resultados y anÃ¡lisis

Los resultados obtenidos se evaluaron principalmente de forma cualitativa, mediante la inspecciÃ³n visual de las imÃ¡genes procesadas, y de forma cuantitativa, a travÃ©s de los porcentajes de ocupaciÃ³n por anaquel. En las pruebas realizadas con imÃ¡genes del conjunto SKU-110K y ejemplos de referencia proporcionados en el repositorio, el sistema fue capaz de identificar correctamente la estructura de los anaqueles en la mayorÃ­a de los casos, incluso cuando existÃ­an ligeras inclinaciones de la cÃ¡mara o variaciones en la iluminaciÃ³n.

La visualizaciÃ³n final, donde cada anaquel se colorea de acuerdo con su nivel de ocupaciÃ³n (por ejemplo, verde para alta ocupaciÃ³n, amarillo para media y rojo para baja), resulta especialmente Ãºtil para la interpretaciÃ³n. Un supervisor puede, de un vistazo, identificar quÃ© zonas requieren reposiciÃ³n. AdemÃ¡s, se calcula una ocupaciÃ³n promedio global de la imagen, Ãºtil para anÃ¡lisis agregados. Comparado con versiones previas del cÃ³digo, el enfoque basado en la mediana de profundidad mostrÃ³ una reducciÃ³n de casos con ocupaciÃ³n reportada como 0% en anaqueles que claramente tenÃ­an productos, lo que indica una mejora en robustez frente a ruido y outliers en el mapa de profundidad.

No obstante, se observaron limitaciones en escenas donde personas u otros objetos ajenos al anaquel ocupaban parte importante de la imagen: el sistema, al basarse en profundidad y estructura geomÃ©trica, puede confundir algunos elementos. Aun asÃ­, en un escenario controlado donde la cÃ¡mara se enfoca a los anaqueles y se minimizan obstrucciones, los resultados son coherentes y repetibles.

### 4.1. Evidencia visual

El sistema genera automÃ¡ticamente:

1. **Una imagen concatenada con los 7 pasos del pipeline**:
   - Imagen original
   - Imagen preprocesada
   - Mapa de bordes (Canny)
   - LÃ­neas detectadas
   - CuadrilÃ¡teros de anaqueles
   - Mapa de profundidad
   - Imagen final con cuadrilÃ¡teros coloreados segÃºn porcentaje de ocupaciÃ³n

2. **Una imagen `*_pipeline_complete.png`** por cada entrada procesada

3. **Overlays con colores**:
   - ğŸŸ¢ **Verde**: alta ocupaciÃ³n (>70%)
   - ğŸŸ¡ **Amarillo**: ocupaciÃ³n media (40â€“70%)
   - ğŸ”´ **Rojo**: ocupaciÃ³n baja (<40%)

### 4.2. Resultados cuantitativos (ejemplos)

De acuerdo con las pruebas documentadas en el repositorio, el mÃ©todo de mediana directa (v1.3.1) mejora significativamente la precisiÃ³n frente a versiones previas con grid/warp:

#### Imagen test_192.jpg
- **MÃ©todo anterior**: 11.8% de ocupaciÃ³n
- **MÃ©todo propuesto**: 34.4% de ocupaciÃ³n

#### Imagen test_179.jpg
- **OcupaciÃ³n estimada**: 18.3%, sin falsos 0%

Asimismo, se reportan mÃ©tricas por anaquel:
- Anaquel 1: 45.2%
- Anaquel 2: 78.5%
- Anaquel 3: 32.1%
- **OcupaciÃ³n promedio**: ~51.9% (en ciertos ejemplos)

### 4.3. AnÃ¡lisis crÃ­tico

**Fortalezas:**

1. La combinaciÃ³n de lÃ­neas estructurales + mapas de profundidad permite distinguir zonas con producto de zonas vacÃ­as, incluso cuando el color de fondo es similar
2. El uso de mediana en lugar de promedios reduce el impacto de valores anÃ³malos en el mapa de profundidad

**Sensibilidades:**

3. El sistema sigue siendo sensible a:
   - Escenas extremadamente saturadas de ruido (personas frente al anaquel)
   - Condiciones de iluminaciÃ³n muy extremas o reflejos intensos
   - Anaqueles con geometrÃ­as no rectilÃ­neas o muy irregulares

### 4.4. Limitaciones y posibles errores

1. **Dependencia del modelo de profundidad**: si el modelo falla (por ejemplo, en dominios muy diferentes al dataset de entrenamiento), la ocupaciÃ³n puede ser sub o sobre-estimada
2. **PÃ©rdida de precisiÃ³n en perspectivas extremas** fuera del rango soportado por la arquitectura de cuadrilÃ¡teros (~âˆ’45Â° a +25Â°)
3. **No reconocimiento de productos individuales**: el sistema detecta anaqueles como estructuras geomÃ©tricas, pero no realiza reconocimiento de productos individuales; por tanto, no distingue entre diferentes tipos de productos, solo mide espacio ocupado vs. vacÃ­o

### 4.5. Propuestas de mejora y trabajo futuro

1. **Integrar un modelo de detecciÃ³n de objetos** para contar productos por anaquel y combinarlo con la ocupaciÃ³n de profundidad
2. **Entrenar/tunear un modelo de profundidad especÃ­fico** para el dominio retail, mejorando la precisiÃ³n en condiciones reales de tienda
3. **Incorporar seguimiento temporal (video)** para detectar en tiempo real cuÃ¡ndo un anaquel alcanza un umbral crÃ­tico de ocupaciÃ³n
4. **DiseÃ±ar una interfaz web** (por ejemplo, con Streamlit) para cargar imÃ¡genes y visualizar resultados en tiempo real

---

## 5. InnovaciÃ³n y complejidad del proyecto

El proyecto destaca por combinar varias ideas que, en conjunto, representan un nivel de innovaciÃ³n y complejidad superior al de ejercicios tÃ­picos de curso. En lugar de limitarse a la detecciÃ³n de bordes o a un clasificador de imÃ¡genes, se plantea un problema aplicado real (ocupaciÃ³n de anaqueles) y se diseÃ±a una soluciÃ³n de extremo a extremo. La decisiÃ³n de trabajar con profundidad monocular es relevante, ya que la mayorÃ­a de soluciones industriales recurren a sensores especializados o a mÃ©todos de conteo de objetos, mientras que aquÃ­ se explota la informaciÃ³n 3D estimada a partir de una sola imagen 2D.

La arquitectura basada en cuadrilÃ¡teros que respetan la perspectiva de la escena tambiÃ©n es un aspecto diferenciador. Muchos enfoques optan por rectificar la imagen completa a una vista "frontal" mediante homografÃ­as, lo que puede introducir distorsiones y requerir supuestos fuertes sobre la calibraciÃ³n de la cÃ¡mara. En este proyecto, en cambio, la detecciÃ³n de lÃ­neas y la construcciÃ³n de cuadrilÃ¡teros permiten trabajar directamente en el espacio de imagen original, preservando la geometrÃ­a sin necesidad de rectificaciÃ³n global.

Desde el punto de vista de ingenierÃ­a, la integraciÃ³n de un modelo de aprendizaje profundo con cÃ³digo tradicional de visiÃ³n computacional, bajo una configuraciÃ³n centralizada y mÃ³dulos bien separados, aproxima el proyecto a un prototipo realista que podrÃ­a evolucionar hacia un producto. Esta combinaciÃ³n de dificultad algorÃ­tmica, integraciÃ³n de librerÃ­as avanzadas y enfoque en un caso de uso concreto justifica considerar el proyecto como de complejidad alta y con un componente de innovaciÃ³n significativo.

### Elementos innovadores y de alta complejidad tÃ©cnica:

1. **Arquitectura basada en cuadrilÃ¡teros adaptativos**: cada anaquel se modela como un cuadrilÃ¡tero que sigue la perspectiva natural, evitando la correcciÃ³n global de perspectiva que tÃ­picamente introduce distorsiones

2. **Uso de un modelo de profundidad de Ãºltima generaciÃ³n** (Depth-Anything-V2) para anÃ¡lisis de ocupaciÃ³n: en lugar de usar Ãºnicamente informaciÃ³n de intensidad o color, el sistema utiliza la dimensiÃ³n de profundidad como seÃ±al principal

3. **MÃ©todo de mediana directa para ocupaciÃ³n**: enfoque simple pero robusto, que mejora la precisiÃ³n y elimina falsos 0% de ocupaciÃ³n

4. **DiseÃ±o modular tipo MLOps**: organizaciÃ³n por capas, configuraciÃ³n centralizada, tests unitarios preparados y lista para integraciÃ³n con herramientas como Streamlit o CI/CD

Esto va mÃ¡s allÃ¡ de un ejemplo bÃ¡sico de detecciÃ³n de bordes o segmentaciÃ³n y constituye un sistema integrado de anÃ¡lisis aplicado a un problema real en retail.

---

## 6. Conclusiones

El desarrollo del "Shelf Occupancy Analyzer" permite concluir que la visiÃ³n computacional, combinada con modelos de profundidad basados en deep learning, constituye una herramienta viable para abordar el problema de monitoreo de anaqueles en el sector retail. El sistema implementado demuestra que, a partir de una sola imagen, es posible segmentar de manera razonablemente robusta los anaqueles, estimar mapas de profundidad y traducir esta informaciÃ³n a un indicador cuantitativo de ocupaciÃ³n, acompaÃ±ado de visualizaciones intuitivas.

En tÃ©rminos de aprendizaje, el proyecto integra varios conceptos clave de la materia: preprocesamiento, detecciÃ³n de caracterÃ­sticas, geometrÃ­a de la imagen, homografÃ­as locales, redes neuronales para tareas de percepciÃ³n y diseÃ±o de pipelines reproducibles. El equipo de trabajo tuvo que enfrentar decisiones de diseÃ±o, compromisos entre precisiÃ³n y costo computacional, asÃ­ como ajustes de parÃ¡metros para obtener resultados estables. Este proceso es representativo de lo que ocurre en proyectos reales de visiÃ³n computacional en la industria.

Si bien el sistema no estÃ¡ exento de limitaciones, especialmente en escenarios con obstrucciones importantes o geometrÃ­as atÃ­picas, constituye una base sÃ³lida sobre la cual construir funcionalidades mÃ¡s avanzadas, como conteo de productos, integraciÃ³n con sistemas de inventario o monitoreo en tiempo real mediante video. En resumen, el proyecto cumple con los objetivos planteados, ofrece un beneficio potencial claro para la operaciÃ³n de tiendas y evidencia el dominio prÃ¡ctico de los temas revisados en el curso.

### Resumen de logros:

El proyecto "Shelf Occupancy Analyzer" demuestra que es posible automatizar el anÃ¡lisis de ocupaciÃ³n de anaqueles mediante una combinaciÃ³n de visiÃ³n computacional clÃ¡sica, estimaciÃ³n de profundidad con deep learning y segmentaciÃ³n geomÃ©trica por cuadrilÃ¡teros. La soluciÃ³n diseÃ±ada logra:

1. âœ… **Detectar anaqueles de forma robusta** a partir de lÃ­neas horizontales y verticales
2. âœ… **Obtener mapas de profundidad fiables** con un modelo preentrenado
3. âœ… **Calcular un porcentaje de ocupaciÃ³n interpretable** por anaquel y visualizarlo de forma intuitiva

Aunque existen limitaciones relacionadas con condiciones extremas de iluminaciÃ³n, geometrÃ­as atÃ­picas y posibles fallos del modelo de profundidad, el sistema proporciona una base sÃ³lida para aplicaciones de monitoreo automatizado en retail y abre la puerta a extensiones orientadas a conteo de productos, alertas en tiempo real y despliegue en aplicaciones web.

---

## 7. Referencias

1. Hui, K., Tang, S., & Chen, X. (2020). *SKU110K: A retail shelf image dataset for product recognition*. arXiv preprint arXiv:2008.09100. https://arxiv.org/abs/2008.09100

2. byed2015. (2024). *Shelf-Occupancy-Analyzer* (versiÃ³n 1.3.x) [Repositorio GitHub]. GitHub. https://github.com/byed2015/shelf-occupancy-analyzer

3. OpenCV. (2024). *OpenCV: Open Source Computer Vision Library â€” Documentation*. https://docs.opencv.org/

4. PyTorch Foundation. (2024). *PyTorch Documentation*. https://pytorch.org/docs/stable/

5. Duda, R. O., & Hart, P. E. (1972). Use of the Hough transformation to detect lines and curves in pictures. *Communications of the ACM*, 15(1), 11â€“15. https://doi.org/10.1145/361237.361242

---

**VersiÃ³n del Sistema**: 2.0.0 (NormalizaciÃ³n Local + Pipeline Simplificado)  
**Fecha del Reporte**: Diciembre 2024  
**Repositorio**: https://github.com/byed2015/shelf-occupancy-analyzer

# GuÃ­a TÃ©cnica Completa - Shelf Occupancy Analyzer

**VersiÃ³n**: 1.2.0 (Arquitectura de CuadrilÃ¡teros Adaptativos)  
**Estado**: âœ… Sistema completo y listo para producciÃ³n

---

## ğŸ“‹ Tabla de Contenidos

1. [InstalaciÃ³n](#instalaciÃ³n)
2. [Uso RÃ¡pido](#uso-rÃ¡pido)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [Pipeline Detallado](#pipeline-detallado)
5. [ConfiguraciÃ³n Avanzada](#configuraciÃ³n-avanzada)
6. [API de Inferencia](#api-de-inferencia)
7. [IntegraciÃ³n con Streamlit](#integraciÃ³n-con-streamlit)
8. [Desarrollo y Testing](#desarrollo-y-testing)
9. [Troubleshooting](#troubleshooting)

---

## ğŸ”§ InstalaciÃ³n

### Requisitos Previos

- **Python**: 3.10 o superior
- **RAM**: 4GB mÃ­nimo, 8GB recomendado
- **GPU**: Opcional (CPU funciona correctamente, GPU acelera ~3-5x)
- **Espacio en disco**: 2GB (modelo + dataset)

### OpciÃ³n 1: InstalaciÃ³n con uv (Recomendado)

```powershell
# Clonar repositorio (si aplica)
git clone <repository-url>
cd shelf-occupancy-analyzer

# Instalar uv si no lo tienes
pip install uv

# Instalar dependencias
uv sync

# Verificar instalaciÃ³n
uv run python -c "print('âœ… InstalaciÃ³n exitosa')"
```

### OpciÃ³n 2: InstalaciÃ³n con pip

```powershell
# Crear entorno virtual
python -m venv .venv

# Activar entorno
# Windows PowerShell:
.\.venv\Scripts\Activate.ps1
# Linux/Mac:
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Verificar instalaciÃ³n
python -c "print('âœ… InstalaciÃ³n exitosa')"
```

### Descargar Dataset de Ejemplo

```powershell
# OpciÃ³n 1: Muestra pequeÃ±a (10 imÃ¡genes, ~50MB)
uv run python -m shelf_occupancy.data.download_dataset --n-samples 10

# OpciÃ³n 2: Muestra completa (50 imÃ¡genes, ~250MB)
uv run python -m shelf_occupancy.data.download_dataset --n-samples 50

# OpciÃ³n 3: Dataset completo (~1.2GB, tarda varios minutos)
uv run python -m shelf_occupancy.data.download_dataset
```

**UbicaciÃ³n**: `data/raw/SKU110K_fixed/images/`

---

## ğŸš€ Uso RÃ¡pido

### 1. Procesar una Imagen Individual

```powershell
# Pipeline completo con visualizaciÃ³n paso a paso
uv run python visualize_pipeline.py \
  --image "data/raw/SKU110K_fixed/images/test_117.jpg" \
  --output-dir "data/results/mi_analisis"
```

**Salida generada**:
- `test_117_pipeline_complete.png` - VisualizaciÃ³n con 7 pasos
- `test_117_report.txt` - Reporte de mÃ©tricas
- `individual_steps/` - Cada paso por separado

### 2. Procesamiento Batch

```powershell
# Procesar mÃºltiples imÃ¡genes y generar CSV
uv run python process_all_images.py \
  --input-dir "data/raw/SKU110K_fixed/images" \
  --output-dir "data/results/batch_analysis" \
  --max-images 20
```

### 3. Uso desde Python (API)

```python
from shelf_occupancy_inference import ShelfOccupancyAnalyzer

# Inicializar analizador
analyzer = ShelfOccupancyAnalyzer()

# Procesar imagen
results = analyzer.process("imagen.jpg")

# Resultados disponibles
print(f"OcupaciÃ³n promedio: {results['avg_occupancy']:.1f}%")
print(f"Anaqueles detectados: {results['num_shelves']}")

for shelf in results['shelves']:
    print(f"  Anaquel {shelf['id']}: {shelf['occupancy']:.1f}%")
```

---

## ğŸ—ï¸ Arquitectura del Sistema

### DiseÃ±o de Alto Nivel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ENTRADA: Imagen RGB             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 1: Preprocesamiento               â”‚
â”‚  - CLAHE (correcciÃ³n iluminaciÃ³n)       â”‚
â”‚  - Filtro bilateral (reducciÃ³n ruido)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 2: DetecciÃ³n de Bordes            â”‚
â”‚  - Canny edge detector                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 3: DetecciÃ³n de LÃ­neas            â”‚
â”‚  - Hough Transform probabilÃ­stico       â”‚
â”‚  - Filtrado ABSOLUTO (H Â±20Â° de 0Â°)     â”‚
â”‚  - FusiÃ³n de lÃ­neas similares           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 4: SegmentaciÃ³n en CuadrilÃ¡teros  â”‚
â”‚  - Clustering DBSCAN de lÃ­neas H        â”‚
â”‚  - Crear cuadrilÃ¡teros de 4 puntos      â”‚
â”‚  - SIN correcciÃ³n de perspectiva        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 5: EstimaciÃ³n de Profundidad      â”‚
â”‚  - Depth-Anything-V2 (CNN)              â”‚
â”‚  - Sobre imagen original (sin distorsi) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 6: AnÃ¡lisis de OcupaciÃ³n          â”‚
â”‚  - Warp local por cuadrilÃ¡tero          â”‚
â”‚  - AnÃ¡lisis de cuadrÃ­cula               â”‚
â”‚  - Refinamiento multi-criterio          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PASO 7: VisualizaciÃ³n y Reporte        â”‚
â”‚  - Heatmaps de ocupaciÃ³n                â”‚
â”‚  - Overlay con mÃ©tricas                 â”‚
â”‚  - Reporte de texto                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitectura de CuadrilÃ¡teros (Novedad v1.2.0)

**Problema Solucionado**: CorrecciÃ³n de perspectiva global distorsionaba imÃ¡genes extremas

**SoluciÃ³n Implementada**:
- Cada anaquel es un **cuadrilÃ¡tero de 4 puntos** (no rectÃ¡ngulo)
- Sigue las **lÃ­neas inclinadas naturales** de la perspectiva
- **Imagen original NO se distorsiona**
- TransformaciÃ³n de perspectiva **LOCAL** solo para anÃ¡lisis

```python
# Estructura del Quadrilateral
class Quadrilateral:
    top_left: (x, y)
    top_right: (x, y)
    bottom_right: (x, y)
    bottom_left: (x, y)
    
    # MÃ©todos clave
    def warp_to_rectangle(image, width, height):
        """Extrae regiÃ³n inclinada y la endereza localmente"""
        # Solo para anÃ¡lisis, NO modifica imagen global
    
    def to_bbox():
        """Convierte a BoundingBox para compatibilidad"""
```

**Ventajas**:
- âœ… Soporta perspectivas extremas (-45Â° a +25Â°)
- âœ… Sin artefactos de distorsiÃ³n
- âœ… Mayor precisiÃ³n en anaqueles inclinados
- âœ… Compatible con cÃ³digo existente (vÃ­a `to_bbox()`)

---

## ğŸ”¬ Pipeline Detallado

### Paso 1: Preprocesamiento

**Clase**: `ImageProcessor` (`src/shelf_occupancy/preprocessing/image_processor.py`)

**Operaciones**:
1. **CLAHE** (Contrast Limited Adaptive Histogram Equalization)
   - Corrige iluminaciÃ³n no uniforme
   - ParÃ¡metros: `clip_limit=2.0`, `tile_grid_size=(8,8)`

2. **Filtro Bilateral**
   - Reduce ruido preservando bordes
   - ParÃ¡metros: `d=9`, `sigma_color=75`, `sigma_space=75`

**ConfiguraciÃ³n** (`config/config.yaml`):
```yaml
preprocessing:
  clahe:
    clip_limit: 2.0
    tile_grid_size: [8, 8]
  bilateral_filter:
    d: 9
    sigma_color: 75
    sigma_space: 75
```

### Paso 2: DetecciÃ³n de Bordes

**Clase**: `EdgeDetector` (`src/shelf_occupancy/detection/edges.py`)

**Algoritmo**: Canny edge detection
- Doble umbral: `low=50`, `high=150`
- SupresiÃ³n de no-mÃ¡ximos
- Seguimiento de bordes por histÃ©resis

**ConfiguraciÃ³n**:
```yaml
shelf_detection:
  canny:
    low_threshold: 50
    high_threshold: 150
    aperture_size: 3
```

### Paso 3: DetecciÃ³n de LÃ­neas

**Clase**: `LineDetector` (`src/shelf_occupancy/detection/lines.py`)

**Algoritmo**: Hough Transform ProbabilÃ­stico (HoughLinesP)

**Filtrado ABSOLUTO (NO adaptativo)**:
- **Horizontales**: `abs(angle) <= 20Â°` o `abs(abs(angle) - 180) <= 20Â°`
- **Verticales**: `abs(abs(angle) - 90) <= 20Â°`

**FusiÃ³n de lÃ­neas**:
- Criterio de Ã¡ngulo: Â±5Â°
- Criterio de distancia: 30 pÃ­xeles

**ConfiguraciÃ³n**:
```yaml
shelf_detection:
  hough:
    threshold: 100
    min_line_length: 100
    max_line_gap: 20
    rho: 1
    theta: 0.017453292  # 1 grado en radianes
```

**CÃ³digo clave**:
```python
# Filtrado absoluto (no adaptativo)
h_lines = line_detector.filter_by_orientation(
    all_lines, "horizontal", tolerance=20, adaptive=False
)
v_lines = line_detector.filter_by_orientation(
    all_lines, "vertical", tolerance=20, adaptive=False
)
```

### Paso 4: SegmentaciÃ³n en CuadrilÃ¡teros

**Clase**: `ShelfDetector` (`src/shelf_occupancy/detection/shelves.py`)

**Proceso**:
1. **Clustering DBSCAN** de lÃ­neas horizontales por coordenada Y
   - `eps=50`, `min_samples=2`
2. **CreaciÃ³n de cuadrilÃ¡teros** entre lÃ­neas consecutivas
   - 4 puntos por anaquel siguiendo inclinaciÃ³n natural
3. **Filtrado** por Ã¡rea mÃ­nima y aspect ratio

**ConfiguraciÃ³n**:
```yaml
shelf_detection:
  clustering:
    eps: 50
    min_samples: 2
  min_shelf_height: 50
  min_shelf_width: 100
```

**CÃ³digo clave**:
```python
# Detectar anaqueles como cuadrilÃ¡teros
shelves = shelf_detector.detect_from_lines(
    h_lines, v_lines, image_shape, 
    use_quadrilaterals=True  # â† Clave
)
```

### Paso 5: EstimaciÃ³n de Profundidad

**Clase**: `DepthEstimator` (`src/shelf_occupancy/depth/estimator.py`)

**Modelo**: Depth-Anything-V2-Small-hf (HuggingFace)
- TamaÃ±o: ~700MB
- Entrada: RGB (cualquier resoluciÃ³n)
- Salida: Mapa de profundidad normalizado [0, 1]

**ConfiguraciÃ³n**:
```yaml
depth_estimation:
  model_name: "depth-anything/Depth-Anything-V2-Small-hf"
  device: "cpu"  # "cuda" si tienes GPU
```

**Nota**: El modelo se descarga automÃ¡ticamente en el primer uso

### Paso 6: AnÃ¡lisis de OcupaciÃ³n

**Clase**: `GridAnalyzer` (`src/shelf_occupancy/analysis/grid_analysis.py`)

**Proceso**:
1. **ExtracciÃ³n local** por cuadrilÃ¡tero
   ```python
   shelf_depth_warped = shelf.warp_to_rectangle(depth_map, width, height)
   ```

2. **SegmentaciÃ³n en cuadrÃ­cula**
   - TamaÃ±o: 10 columnas Ã— 5 filas (configurable)

3. **Refinamiento multi-criterio**:
   - DetecciÃ³n de fondo (percentil de profundidad)
   - AnÃ¡lisis de textura (varianza local)
   - Filtrado de mÃ¡rgenes

4. **CÃ¡lculo de ocupaciÃ³n**
   - Por celda, por anaquel, promedio global

**ConfiguraciÃ³n**:
```yaml
occupancy_analysis:
  grid_size: [10, 5]  # [cols, rows]
  thresholds:
    depth_percentile: 0.3
    min_occupancy: 0.2
    variance_threshold: 0.01
    margin_threshold: 0.15
```

### Paso 7: VisualizaciÃ³n

**Clase**: `OccupancyVisualizer` (`src/shelf_occupancy/visualization/overlay.py`)

**Salidas**:
- Heatmap de ocupaciÃ³n por anaquel
- Overlay con bounding boxes y porcentajes
- VisualizaciÃ³n concatenada de 7 pasos
- Reporte de texto con mÃ©tricas

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Archivo Principal: `config/config.yaml`

```yaml
# PREPROCESAMIENTO
preprocessing:
  clahe:
    clip_limit: 2.0           # â†‘ = mÃ¡s contraste
    tile_grid_size: [8, 8]    # TamaÃ±o de grid adaptativo
  bilateral_filter:
    d: 9                      # DiÃ¡metro del kernel
    sigma_color: 75           # â†‘ = mÃ¡s suavizado de color
    sigma_space: 75           # â†‘ = mÃ¡s alcance espacial

# DETECCIÃ“N DE ESTRUCTURA
shelf_detection:
  canny:
    low_threshold: 50         # â†“ = mÃ¡s bordes (mÃ¡s sensible)
    high_threshold: 150
    aperture_size: 3
  
  hough:
    threshold: 100            # â†“ = mÃ¡s lÃ­neas (mÃ¡s sensible)
    min_line_length: 100      # Longitud mÃ­nima de lÃ­nea
    max_line_gap: 20          # MÃ¡ximo gap para unir lÃ­neas
  
  clustering:
    eps: 50                   # Distancia para agrupar lÃ­neas
    min_samples: 2            # MÃ­nimo de lÃ­neas por cluster
  
  min_shelf_height: 50        # Filtro por tamaÃ±o
  min_shelf_width: 100

# ESTIMACIÃ“N DE PROFUNDIDAD
depth_estimation:
  model_name: "depth-anything/Depth-Anything-V2-Small-hf"
  device: "cpu"               # "cuda" para GPU
  enable_bilateral: true      # Post-procesamiento

# ANÃLISIS DE OCUPACIÃ“N
occupancy_analysis:
  grid_size: [10, 5]          # [cols, rows] - mÃ¡s fino = mÃ¡s detalle
  
  thresholds:
    depth_percentile: 0.3     # â†‘ = menos ocupaciÃ³n detectada
    min_occupancy: 0.2        # Umbral para considerar ocupado
    variance_threshold: 0.01  # DetecciÃ³n de textura
    margin_threshold: 0.15    # % de margen a ignorar

  refinement:
    enable: true              # Activar refinamiento
    background_detection: true
    texture_analysis: true
    margin_filter: true

# VISUALIZACIÃ“N
visualization:
  colormap: "jet"             # Colormap para heatmaps
  alpha: 0.5                  # Transparencia de overlay
  show_grid: true             # Mostrar cuadrÃ­cula
  font_scale: 0.6
```

### Ajustes Comunes

**Para perspectivas extremas**:
```yaml
shelf_detection:
  hough:
    threshold: 80             # MÃ¡s sensible
  clustering:
    eps: 70                   # MÃ¡s tolerante
```

**Para mayor precisiÃ³n**:
```yaml
occupancy_analysis:
  grid_size: [15, 8]          # CuadrÃ­cula mÃ¡s fina
  thresholds:
    variance_threshold: 0.005 # MÃ¡s estricto
```

**Para GPU**:
```yaml
depth_estimation:
  device: "cuda"
```

---

## ğŸ”Œ API de Inferencia

### Clase Principal: `ShelfOccupancyAnalyzer`

**UbicaciÃ³n**: `shelf_occupancy_inference.py`

**Ejemplo Completo**:

```python
from shelf_occupancy_inference import ShelfOccupancyAnalyzer
import cv2

# 1. Inicializar
analyzer = ShelfOccupancyAnalyzer()

# 2. Procesar imagen
results = analyzer.process(
    image_input="imagen.jpg",
    return_visualizations=True,
    return_steps=True
)

# 3. Acceder a resultados
print(f"OcupaciÃ³n promedio: {results['avg_occupancy']:.1f}%")
print(f"Anaqueles: {results['num_shelves']}")

for shelf in results['shelves']:
    print(f"  Anaquel {shelf['id']}")
    print(f"    OcupaciÃ³n: {shelf['occupancy']:.1f}%")
    print(f"    Celdas ocupadas: {shelf['stats']['occupied_cells']}")

# 4. Guardar visualizaciones
cv2.imwrite("pipeline.jpg", results['pipeline_image'])
cv2.imwrite("overlay.jpg", results['overlay_image'])

# 5. Acceder a pasos intermedios (si return_steps=True)
cv2.imwrite("edges.jpg", results['steps']['edges'])
cv2.imwrite("lines.jpg", results['steps']['lines'])
```

### Estructura de `results`

```python
{
    'avg_occupancy': float,        # Porcentaje promedio
    'num_shelves': int,            # NÃºmero de anaqueles
    'shelves': [                   # Lista de anaqueles
        {
            'id': int,
            'occupancy': float,
            'stats': {
                'occupied_cells': int,
                'total_cells': int,
                'min_occupancy': float,
                'max_occupancy': float,
                'std_occupancy': float
            }
        },
        ...
    ],
    'pipeline_image': np.ndarray,  # VisualizaciÃ³n completa
    'overlay_image': np.ndarray,   # Overlay con ocupaciÃ³n
    'steps': {                     # Pasos intermedios (opcional)
        'preprocessed': np.ndarray,
        'edges': np.ndarray,
        'lines': np.ndarray,
        'shelves': np.ndarray,
        'depth': np.ndarray
    }
}
```

---

## ğŸ¨ IntegraciÃ³n con Streamlit

### Ejemplo de App BÃ¡sica

Crear `streamlit_app.py`:

```python
import streamlit as st
import cv2
import numpy as np
from PIL import Image
from shelf_occupancy_inference import ShelfOccupancyAnalyzer

# Configurar pÃ¡gina
st.set_page_config(
    page_title="Shelf Occupancy Analyzer",
    page_icon="ğŸ“¦",
    layout="wide"
)

# TÃ­tulo
st.title("ğŸ“¦ Analizador de OcupaciÃ³n de Anaqueles")
st.markdown("Sube una imagen de un anaquel para analizar su nivel de ocupaciÃ³n")

# Sidebar con configuraciÃ³n
st.sidebar.header("âš™ï¸ ConfiguraciÃ³n")
show_steps = st.sidebar.checkbox("Mostrar pasos intermedios", value=False)
show_metrics = st.sidebar.checkbox("Mostrar mÃ©tricas detalladas", value=True)

# Cache del analizador
@st.cache_resource
def load_analyzer():
    return ShelfOccupancyAnalyzer()

analyzer = load_analyzer()

# Upload de imagen
uploaded_file = st.file_uploader(
    "Selecciona una imagen", 
    type=['jpg', 'jpeg', 'png']
)

if uploaded_file is not None:
    # Leer imagen
    image = Image.open(uploaded_file)
    image_array = np.array(image)
    
    # Mostrar imagen original
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“¸ Imagen Original")
        st.image(image, use_column_width=True)
    
    # Procesar con spinner
    with st.spinner('ğŸ”„ Procesando imagen...'):
        results = analyzer.process(
            image_array,
            return_visualizations=True,
            return_steps=show_steps
        )
    
    # Mostrar resultados principales
    with col2:
        st.subheader("ğŸ“Š Resultados")
        
        # MÃ©trica principal
        st.metric(
            label="OcupaciÃ³n Promedio",
            value=f"{results['avg_occupancy']:.1f}%",
            delta=None
        )
        
        # Anaqueles detectados
        st.metric(
            label="Anaqueles Detectados",
            value=results['num_shelves']
        )
        
        # VisualizaciÃ³n overlay
        st.image(
            cv2.cvtColor(results['overlay_image'], cv2.COLOR_BGR2RGB),
            caption="AnÃ¡lisis de OcupaciÃ³n",
            use_column_width=True
        )
    
    # MÃ©tricas detalladas
    if show_metrics:
        st.subheader("ğŸ“‹ Detalle por Anaquel")
        
        cols = st.columns(min(3, len(results['shelves'])))
        for idx, shelf in enumerate(results['shelves']):
            with cols[idx % 3]:
                st.metric(
                    label=f"Anaquel {shelf['id']}",
                    value=f"{shelf['occupancy']:.1f}%"
                )
                with st.expander("Ver estadÃ­sticas"):
                    st.write(f"Celdas ocupadas: {shelf['stats']['occupied_cells']}")
                    st.write(f"Total celdas: {shelf['stats']['total_cells']}")
                    st.write(f"OcupaciÃ³n mÃ­n: {shelf['stats']['min_occupancy']:.2f}")
                    st.write(f"OcupaciÃ³n mÃ¡x: {shelf['stats']['max_occupancy']:.2f}")
    
    # Pipeline completo
    st.subheader("ğŸ”¬ Pipeline de Procesamiento")
    st.image(
        cv2.cvtColor(results['pipeline_image'], cv2.COLOR_BGR2RGB),
        caption="VisualizaciÃ³n de 7 pasos del pipeline",
        use_column_width=True
    )
    
    # Pasos intermedios (si se activÃ³)
    if show_steps and 'steps' in results:
        st.subheader("ğŸ” Pasos Intermedios")
        
        step_cols = st.columns(3)
        steps_to_show = [
            ('preprocessed', 'Preprocesamiento'),
            ('edges', 'DetecciÃ³n de Bordes'),
            ('lines', 'DetecciÃ³n de LÃ­neas')
        ]
        
        for idx, (step_key, step_name) in enumerate(steps_to_show):
            if step_key in results['steps']:
                with step_cols[idx]:
                    img = results['steps'][step_key]
                    if len(img.shape) == 2:  # Grayscale
                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
                    else:
                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    st.image(img, caption=step_name)

else:
    # Instrucciones
    st.info("ğŸ‘† Sube una imagen para comenzar el anÃ¡lisis")
    
    # Mostrar ejemplo
    st.subheader("ğŸ“– CÃ³mo funciona")
    st.markdown("""
    Este sistema analiza la ocupaciÃ³n de anaqueles en 7 pasos:
    
    1. **Preprocesamiento**: Mejora de contraste y reducciÃ³n de ruido
    2. **DetecciÃ³n de Bordes**: Identifica contornos con Canny
    3. **DetecciÃ³n de LÃ­neas**: Encuentra lÃ­neas horizontales y verticales
    4. **SegmentaciÃ³n**: Crea cuadrilÃ¡teros que siguen la perspectiva
    5. **Profundidad**: Estima distancia con modelo CNN
    6. **AnÃ¡lisis**: Calcula ocupaciÃ³n con refinamiento
    7. **VisualizaciÃ³n**: Genera overlays y reportes
    
    **Ventajas**:
    - âœ… Funciona con perspectivas extremas (-45Â° a +25Â°)
    - âœ… Sin distorsiÃ³n de imagen original
    - âœ… Refinamiento automÃ¡tico (~20% mÃ¡s preciso)
    """)

# Footer
st.markdown("---")
st.markdown("v1.2.0 | Arquitectura de CuadrilÃ¡teros Adaptativos")
```

### Ejecutar App

```powershell
# Instalar Streamlit
uv pip install streamlit

# Ejecutar app
streamlit run streamlit_app.py
```

---

## ğŸ§ª Desarrollo y Testing

### Ejecutar Tests

```powershell
# Todos los tests
uv run pytest

# Con cobertura
uv run pytest --cov=src --cov-report=html

# Test especÃ­fico
uv run pytest tests/test_preprocessing.py -v

# Con logs detallados
uv run pytest -v -s
```

### Estructura de Tests

```
tests/
â”œâ”€â”€ test_preprocessing.py    # Tests de preprocesamiento
â”œâ”€â”€ test_detection.py         # Tests de detecciÃ³n
â”œâ”€â”€ test_depth.py             # Tests de profundidad
â””â”€â”€ test_analysis.py          # Tests de anÃ¡lisis
```

### Agregar Nuevos Tests

```python
# tests/test_ejemplo.py
import pytest
import numpy as np
from shelf_occupancy.preprocessing import ImageProcessor

def test_preprocesamiento_normaliza():
    """Test que preprocesamiento normaliza dimensiones."""
    processor = ImageProcessor()
    
    # Imagen de prueba
    image = np.random.randint(0, 255, (1000, 800, 3), dtype=np.uint8)
    
    # Procesar
    processed = processor.preprocess(image)
    
    # Verificar
    assert processed.shape[0] <= 1024
    assert processed.shape[1] <= 1024
    assert processed.dtype == np.uint8
```

---

## ğŸ”§ Troubleshooting

### Error: "CUDA no disponible"

**SoluciÃ³n**: El sistema usa CPU automÃ¡ticamente. No requiere acciÃ³n.

**Para forzar GPU** (si tienes):
```yaml
# config/config.yaml
depth_estimation:
  device: "cuda"
```

### Error: "No se encontraron imÃ¡genes"

**SoluciÃ³n**: Descarga dataset de ejemplo
```powershell
uv run python -m shelf_occupancy.data.download_dataset --n-samples 10
```

### OcupaciÃ³n parece incorrecta (muy alta/baja)

**SoluciÃ³n 1**: Ajustar umbral de profundidad
```yaml
occupancy_analysis:
  thresholds:
    depth_percentile: 0.4  # â†‘ = menos ocupaciÃ³n
```

**SoluciÃ³n 2**: Ajustar sensibilidad de detecciÃ³n
```yaml
shelf_detection:
  hough:
    threshold: 80  # â†“ = mÃ¡s lÃ­neas detectadas
```

### LÃ­neas no detectan anaqueles correctamente

**SoluciÃ³n**: Aumentar tolerancia angular (perspectivas extremas)
```python
# En visualize_pipeline.py, cambiar:
h_lines = line_detector.filter_by_orientation(
    all_lines, "horizontal", tolerance=25, adaptive=False  # â† Aumentar
)
```

### Modelo tarda mucho en descargar

**Causa**: Modelo Depth-Anything-V2 pesa ~700MB

**SoluciÃ³n**: 
- Primera ejecuciÃ³n tarda (descarga automÃ¡tica)
- Subsecuentes usan cache local
- UbicaciÃ³n cache: `~/.cache/huggingface/`

### Error de memoria

**SoluciÃ³n**: Reducir tamaÃ±o de batch o resoluciÃ³n
```yaml
preprocessing:
  max_dimension: 800  # Reducir de 1024
```

---

## ğŸ“š Referencias

- [Depth-Anything-V2](https://huggingface.co/depth-anything/Depth-Anything-V2-Small-hf)
- [SKU-110K Dataset](https://github.com/eg4000/SKU110K_CVPR19)
- [OpenCV Hough Transform](https://docs.opencv.org/4.x/d9/db0/tutorial_hough_lines.html)
- [Streamlit Documentation](https://docs.streamlit.io/)

---

**Â¿Necesitas mÃ¡s ayuda?**  
Consulta los notebooks en `notebooks/` para ejemplos interactivos.

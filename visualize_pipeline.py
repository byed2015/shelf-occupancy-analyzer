"""
Script para visualizar el pipeline completo paso a paso.

Este script procesa una imagen a travÃ©s de todas las etapas del pipeline
y genera visualizaciones de cada paso, guardÃ¡ndolas individualmente y
concatenadas en una Ãºnica imagen resumen.

Uso:
    # Procesar una imagen especÃ­fica
    uv run python visualize_pipeline.py --image data/raw/sample/sku110k_sample_000.jpg
    
    # Usar la primera imagen disponible
    uv run python visualize_pipeline.py
    
    # Con configuraciÃ³n personalizada
    uv run python visualize_pipeline.py --config config/config.yaml
"""

import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import cv2
import matplotlib.pyplot as plt
import numpy as np
from loguru import logger

from shelf_occupancy.analysis import GridAnalyzer
from shelf_occupancy.config import load_config
from shelf_occupancy.depth import DepthEstimator
from shelf_occupancy.detection import EdgeDetector, LineDetector, ShelfDetector
from shelf_occupancy.preprocessing import ImagePreprocessor
from shelf_occupancy.utils import load_image, save_image
from shelf_occupancy.visualization import OccupancyVisualizer


class PipelineVisualizer:
    """Visualizador del pipeline completo paso a paso."""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """
        Inicializa el visualizador.
        
        Args:
            config_path: Ruta al archivo de configuraciÃ³n
        """
        self.config = load_config(config_path)
        self.steps: Dict[str, np.ndarray] = {}
        self.step_info: Dict[str, str] = {}
        
        logger.info("PipelineVisualizer inicializado")
    
    def process_image(self, image_path: Path) -> bool:
        """
        Procesa una imagen a travÃ©s del pipeline completo.
        
        Args:
            image_path: Ruta a la imagen
        
        Returns:
            True si el procesamiento fue exitoso
        """
        logger.info("=" * 80)
        logger.info(f"ðŸš€ VISUALIZACIÃ“N DEL PIPELINE COMPLETO")
        logger.info("=" * 80)
        logger.info(f"ðŸ“ Imagen: {image_path.name}\n")
        
        try:
            # Paso 0: Cargar imagen original
            logger.info("ðŸ“· PASO 0: Carga de imagen")
            original = load_image(image_path, color_mode="BGR")
            self.steps['0_original'] = original.copy()
            self.step_info['0_original'] = f"Original\n{original.shape[1]}x{original.shape[0]}"
            logger.info(f"   âœ“ Imagen cargada: {original.shape}\n")
            
            # Paso 1: ConversiÃ³n a escala de grises (Ãºnico preprocesamiento necesario)
            logger.info("ðŸ”§ PASO 1: ConversiÃ³n a escala de grises")
            gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
            
            # Aplicar suavizado gaussiano ligero para reducir ruido
            gray_smooth = cv2.GaussianBlur(gray, (5, 5), 1.0)
            
            gray_bgr = cv2.cvtColor(gray_smooth, cv2.COLOR_GRAY2BGR)
            self.steps['1_preprocessed'] = gray_bgr
            self.step_info['1_preprocessed'] = "Escala de Grises\n+ Gaussian Blur"
            logger.info(f"   âœ“ ConversiÃ³n a escala de grises")
            logger.info(f"   âœ“ Suavizado gaussiano aplicado\n")
            
            # Paso 2: DetecciÃ³n de bordes (Canny optimizado)
            logger.info("ðŸ” PASO 2: DetecciÃ³n de bordes")
            # Canny con auto-threshold (mÃ¡s robusto)
            median_val = np.median(gray_smooth)
            lower = int(max(0, 0.66 * median_val))
            upper = int(min(255, 1.33 * median_val))
            edges = cv2.Canny(gray_smooth, lower, upper, apertureSize=3)
            
            edges_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
            self.steps['2_edges'] = edges_bgr
            self.step_info['2_edges'] = f"Bordes (Canny Auto)\nUmbrales: {lower}/{upper}"
            logger.info(f"   âœ“ Bordes detectados (auto-threshold: {lower}/{upper})\n")
            
            # Paso 3: DetecciÃ³n de lÃ­neas con perspectiva adaptativa
            logger.info("ðŸ“ PASO 3: DetecciÃ³n de lÃ­neas")
            line_detector = LineDetector(self.config.shelf_detection.hough)
            
            # Usar HoughLinesP normal (mÃ¡s rÃ¡pido)
            all_lines = line_detector.detect(edges, use_polar=False)
            logger.info(f"   âœ“ {len(all_lines)} lÃ­neas detectadas")
            
            # Filtrado ABSOLUTO (no adaptativo): horizontal cerca de 0Â°, vertical cerca de Â±90Â°
            # Tolerancia de 20Â° captura perspectivas moderadas sin confundir orientaciones
            h_lines = line_detector.filter_by_orientation(all_lines, "horizontal", tolerance=20, adaptive=False)
            v_lines = line_detector.filter_by_orientation(all_lines, "vertical", tolerance=20, adaptive=False)
            
            # Detectar Ã¡ngulo dominante para visualizaciÃ³n
            dominant_angle_h = line_detector.detect_dominant_angle(h_lines) if h_lines else 0.0
            dominant_angle_v = line_detector.detect_dominant_angle(v_lines) if v_lines else 90.0
            
            # Fusionar lÃ­neas similares
            h_lines = line_detector.merge_similar_lines(h_lines, angle_threshold=5, distance_threshold=30)
            v_lines = line_detector.merge_similar_lines(v_lines, angle_threshold=5, distance_threshold=30)
            
            # Visualizar lÃ­neas con colores segÃºn Ã¡ngulo
            lines_img = original.copy()
            
            # Dibujar horizontales en verde con intensidad segÃºn cercanÃ­a a Ã¡ngulo dominante
            for line in h_lines:
                angle_diff = line_detector._angle_difference(line.angle, dominant_angle_h)
                intensity = int(255 * (1 - angle_diff / 15))  # MÃ¡s brillante = mÃ¡s cercano
                cv2.line(lines_img, (int(line.x1), int(line.y1)), (int(line.x2), int(line.y2)), (0, max(100, intensity), 0), 2)
            
            # Dibujar verticales en azul
            for line in v_lines:
                angle_diff = line_detector._angle_difference(line.angle, dominant_angle_v)
                intensity = int(255 * (1 - angle_diff / 15))
                cv2.line(lines_img, (int(line.x1), int(line.y1)), (int(line.x2), int(line.y2)), (max(100, intensity), 0, 0), 2)
            
            # Agregar texto con Ã¡ngulo dominante
            cv2.putText(
                lines_img,
                f"Horizontal: {dominant_angle_h:.1f}deg",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,
                (0, 255, 0),
                2
            )
            cv2.putText(
                lines_img,
                f"Vertical: {dominant_angle_v:.1f}deg",
                (10, 70),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,
                (255, 0, 0),
                2
            )
            
            self.steps['3_lines'] = lines_img
            self.step_info['3_lines'] = f"LÃ­neas (Hough Polar)\nH:{len(h_lines)}@{dominant_angle_h:.1f}Â° V:{len(v_lines)}@{dominant_angle_v:.1f}Â°"
            logger.info(f"   âœ“ {len(h_lines)} lÃ­neas horizontales @ {dominant_angle_h:.1f}Â°")
            logger.info(f"   âœ“ {len(v_lines)} lÃ­neas verticales @ {dominant_angle_v:.1f}Â°\n")
            
            # Paso 4: DetecciÃ³n de anaqueles como cuadrilÃ¡teros inclinados
            # NO corregimos perspectiva, segmentamos siguiendo las lÃ­neas naturales
            logger.info("ðŸ“¦ PASO 4: DetecciÃ³n de anaqueles (cuadrilÃ¡teros inclinados)")
            shelf_detector = ShelfDetector(self.config.shelf_detection)
            
            # Detectar anaqueles sin objetos (mÃ©todo simplificado)
            shelves = shelf_detector.detect_from_lines(
                h_lines, 
                v_lines, 
                original.shape[:2], 
                use_quadrilaterals=True,
                detected_objects=None  # No usar objetos para refinamiento
            )
            
            if not shelves:
                logger.warning("   âš  No se detectaron anaqueles, usando cuadrÃ­cula simple")
                shelves = shelf_detector.detect_simple_grid(original.shape[:2], n_rows=4)
            
            # FILTRADO GEOMÃ‰TRICO MEJORADO (sin YOLO)
            logger.info(f"ðŸ” Filtrando anaqueles por geometrÃ­a y posiciÃ³n...")
            valid_shelves = []
            
            for i, shelf in enumerate(shelves):
                # ValidaciÃ³n geomÃ©trica: no piso ni techo
                center_y = shelf.center[1]
                image_height = original.shape[0]
                is_floor = center_y > image_height * 0.85  # 15% inferior
                is_ceiling = center_y < image_height * 0.05  # 5% superior
                
                # Validar Ã¡rea mÃ­nima
                if hasattr(shelf, 'get_area'):
                    area = shelf.get_area()
                else:
                    area = shelf.width * shelf.height if hasattr(shelf, 'width') else 1000000
                
                min_area = image_height * 100  # Ãrea mÃ­nima proporcional a imagen
                is_too_small = area < min_area
                
                # Validar aspect ratio (anaqueles son mÃ¡s anchos que altos)
                if hasattr(shelf, 'width') and hasattr(shelf, 'height'):
                    aspect_ratio = shelf.width / shelf.height if shelf.height > 0 else 0
                    is_valid_ratio = 1.5 < aspect_ratio < 50  # Anaqueles tÃ­picamente 2:1 a 20:1
                else:
                    is_valid_ratio = True  # Asumir vÃ¡lido si no podemos calcular
                
                # Decidir si es vÃ¡lido
                if not is_floor and not is_ceiling and not is_too_small and is_valid_ratio:
                    valid_shelves.append(shelf)
                    logger.info(f"   âœ“ Anaquel {i+1}: Ã¡rea={area:.0f}pxÂ² - VÃLIDO")
                else:
                    reason = "piso" if is_floor else ("techo" if is_ceiling else ("muy pequeÃ±o" if is_too_small else "aspect ratio invÃ¡lido"))
                    logger.warning(f"   âœ— Anaquel {i+1}: Ã¡rea={area:.0f}pxÂ² - DESCARTADO ({reason})")
            
            if valid_shelves:
                logger.info(f"   âœ“ Anaqueles vÃ¡lidos: {len(valid_shelves)}/{len(shelves)}")
                shelves = valid_shelves
            else:
                logger.warning("   âš  No hay anaqueles vÃ¡lidos tras filtrado, usando todos")
            
            # Visualizar anaqueles (dibujar cuadrilÃ¡teros inclinados)
            shelves_img = original.copy()
            for i, shelf in enumerate(shelves):
                # Obtener puntos del cuadrilÃ¡tero
                if hasattr(shelf, 'get_corners'):  # Es Quadrilateral
                    corners = shelf.get_corners().astype(np.int32)
                    cv2.polylines(shelves_img, [corners], True, (0, 255, 255), 3)
                    
                    # Dibujar puntos de esquina para claridad visual
                    for corner in corners:
                        cv2.circle(shelves_img, tuple(corner), 8, (0, 0, 255), -1)
                    
                    # Etiqueta en centro
                    center = shelf.center
                    cv2.putText(
                        shelves_img,
                        f"S{i+1}",
                        (int(center[0]) - 20, int(center[1])),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1.2,
                        (0, 255, 255),
                        3
                    )
                else:  # Es BoundingBox
                    cv2.rectangle(
                        shelves_img,
                        (shelf.x, shelf.y),
                        (shelf.x + shelf.width, shelf.y + shelf.height),
                        (0, 255, 255),
                        3
                    )
                    cv2.putText(
                        shelves_img,
                        f"S{i+1}",
                        (shelf.x + 10, shelf.y + 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1.0,
                        (0, 255, 255),
                        2
                    )
            
            self.steps['4_shelves'] = shelves_img
            self.step_info['4_shelves'] = f"Anaqueles (CuadrilÃ¡teros)\n{len(shelves)} detectados"
            logger.info(f"   âœ“ {len(shelves)} anaqueles detectados\n")
            
            # Paso 5: EstimaciÃ³n de profundidad (usar imagen original)
            logger.info("ðŸŒŠ PASO 5: EstimaciÃ³n de profundidad")
            depth_estimator = DepthEstimator(self.config.depth_estimation)
            depth_map, depth_colored = depth_estimator.estimate(original, return_colored=True)
            
            # Convertir depth_colored de RGB a BGR para OpenCV
            depth_colored_bgr = cv2.cvtColor(depth_colored, cv2.COLOR_RGB2BGR)
            self.steps['5_depth'] = depth_colored_bgr
            self.step_info['5_depth'] = f"Profundidad\nRango: [{depth_map.min():.2f}, {depth_map.max():.2f}]"
            logger.info(f"   âœ“ Mapa de profundidad generado")
            logger.info(f"   âœ“ Rango: [{depth_map.min():.3f}, {depth_map.max():.3f}]\n")
            
            # Paso 6: AnÃ¡lisis de ocupaciÃ³n (NORMALIZACIÃ“N POR CUADRILÃTERO)
            logger.info("ðŸ“Š PASO 6: AnÃ¡lisis de ocupaciÃ³n (normalizaciÃ³n independiente por anaquel)")
            
            # Para cada anaquel (cuadrilÃ¡tero), calcular ocupaciÃ³n con normalizaciÃ³n local
            occupancy_percentages = []
            stats_list = []
            
            for i, shelf in enumerate(shelves):
                if hasattr(shelf, 'get_corners'):  # Es Quadrilateral
                    # Crear mÃ¡scara del cuadrilÃ¡tero en la imagen
                    mask = np.zeros(depth_map.shape[:2], dtype=np.uint8)
                    corners = shelf.get_corners().astype(np.int32)
                    cv2.fillPoly(mask, [corners], 1)
                    
                    # Extraer profundidades dentro del cuadrilÃ¡tero
                    shelf_depth_values = depth_map[mask == 1]
                    
                    if shelf_depth_values.size > 0:
                        # ðŸ”¥ NORMALIZACIÃ“N LOCAL POR CUADRILÃTERO
                        # Medir min/max DENTRO del cuadrilÃ¡tero (no de la imagen completa)
                        depth_min = np.min(shelf_depth_values)
                        depth_max = np.max(shelf_depth_values)
                        depth_range = depth_max - depth_min
                        
                        # Normalizar profundidades al rango [0, 1] LOCAL
                        if depth_range > 0.01:  # Evitar divisiÃ³n por cero
                            normalized_depths = (shelf_depth_values - depth_min) / depth_range
                        else:
                            # Si el rango es muy pequeÃ±o, asumir uniforme
                            normalized_depths = np.ones_like(shelf_depth_values) * 0.5
                        
                        # Calcular mediana de profundidades normalizadas
                        median_normalized = np.median(normalized_depths)
                        mean_normalized = np.mean(normalized_depths)
                        
                        # InterpretaciÃ³n:
                        # - median_normalized cercano a 0 = mayorÃ­a de pÃ­xeles cerca del fondo (vacÃ­o)
                        # - median_normalized cercano a 1 = mayorÃ­a de pÃ­xeles cerca del frente (lleno)
                        # Por lo tanto: ocupaciÃ³n = median_normalized * 100
                        
                        occupancy = median_normalized * 100  # Convertir a porcentaje
                        
                        logger.info(f"   Anaquel {i+1}:")
                        logger.info(f"      â†’ Rango profundidad: [{depth_min:.3f}, {depth_max:.3f}]")
                        logger.info(f"      â†’ Mediana normalizada: {median_normalized:.3f}")
                        logger.info(f"      â†’ Media normalizada: {mean_normalized:.3f}")
                        logger.info(f"      â†’ OcupaciÃ³n: {occupancy:.1f}%")
                        
                        occupancy_percentages.append(occupancy)
                        stats_list.append({
                            'mean_occupancy': float(mean_normalized),
                            'median_occupancy': float(median_normalized),
                            'std_occupancy': float(np.std(normalized_depths)),
                            'min_occupancy': float(np.min(normalized_depths)),
                            'max_occupancy': float(np.max(normalized_depths)),
                            'depth_min': float(depth_min),
                            'depth_max': float(depth_max),
                            'depth_range': float(depth_range),
                            'occupied_cells': int(np.sum(normalized_depths > 0.3)),
                            'total_cells': int(shelf_depth_values.size)
                        })
                    else:
                        logger.warning(f"   Anaquel {i+1}: Sin valores de profundidad vÃ¡lidos")
                        occupancy_percentages.append(0.0)
                        stats_list.append({})
                else:  # BoundingBox tradicional
                    shelf_region = depth_map[shelf.y1:shelf.y2, shelf.x1:shelf.x2]
                    if shelf_region.size > 0:
                        depth_min = np.min(shelf_region)
                        depth_max = np.max(shelf_region)
                        depth_range = depth_max - depth_min
                        
                        if depth_range > 0.01:
                            normalized = (shelf_region - depth_min) / depth_range
                            median_normalized = np.median(normalized)
                        else:
                            median_normalized = 0.5
                        
                        occupancy = median_normalized * 100
                        occupancy_percentages.append(occupancy)
                        stats_list.append({})
                    else:
                        occupancy_percentages.append(0.0)
                        stats_list.append({})
            
            # Paso 6.5: VisualizaciÃ³n combinada (cuadrilÃ¡teros + depth)
            logger.info("\nðŸ”— PASO 6.5: VisualizaciÃ³n combinada (anaqueles + profundidad)")
            
            # Vista combinada simplificada - depth en escala de grises + anaqueles
            combined_view = original.copy()
            
            # 1. Aplicar mapa de profundidad en escala de grises (sutil)
            depth_norm = ((depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255).astype(np.uint8)
            depth_gray = cv2.cvtColor(cv2.applyColorMap(depth_norm, cv2.COLORMAP_BONE), cv2.COLOR_BGR2GRAY)
            depth_gray_3ch = cv2.cvtColor(depth_gray, cv2.COLOR_GRAY2BGR)
            cv2.addWeighted(depth_gray_3ch, 0.25, combined_view, 0.75, 0, combined_view)
            
            # 2. Dibujar cuadrilÃ¡teros de anaqueles
            for i, shelf in enumerate(shelves):
                if hasattr(shelf, 'get_corners'):
                    corners = shelf.get_corners().astype(np.int32)
                    # LÃ­neas cian gruesas para anaqueles
                    cv2.polylines(combined_view, [corners], True, (255, 255, 0), 4)
                    
                    # Etiqueta simple
                    center = shelf.center
                    label = f"A{i+1}"
                    (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
                    
                    # Fondo semi-transparente para la etiqueta
                    overlay = combined_view.copy()
                    cv2.rectangle(overlay, 
                                (int(center[0]) - text_w//2 - 5, int(center[1]) - text_h//2 - 5),
                                (int(center[0]) + text_w//2 + 5, int(center[1]) + text_h//2 + 5),
                                (0, 0, 0), -1)
                    cv2.addWeighted(overlay, 0.6, combined_view, 0.4, 0, combined_view)
                    
                    cv2.putText(
                        combined_view,
                        label,
                        (int(center[0]) - text_w//2, int(center[1]) + text_h//2),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.8,
                        (255, 255, 0),
                        2
                    )
                else:
                    cv2.rectangle(
                        combined_view,
                        (shelf.x1, shelf.y1),
                        (shelf.x2, shelf.y2),
                        (255, 255, 0),
                        4
                    )
            
            # Agregar leyenda
            legend_y = 35
            legend_bg = combined_view.copy()
            cv2.rectangle(legend_bg, (5, 5), (550, 50), (0, 0, 0), -1)
            cv2.addWeighted(legend_bg, 0.7, combined_view, 0.3, 0, combined_view)
            
            cv2.putText(combined_view, "Amarillo: Anaqueles | Fondo: Profundidad (gris)", 
                       (10, legend_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            self.steps['6.5_combined'] = combined_view
            self.step_info['6.5_combined'] = f"Vista Combinada\n{len(shelves)} anaqueles"
            logger.info(f"   âœ“ Vista combinada creada")
            logger.info(f"   âœ“ Anaqueles vÃ¡lidos: {len(shelves)}\n")
            
            # Paso 7: VisualizaciÃ³n final
            logger.info("\nðŸŽ¨ PASO 7: VisualizaciÃ³n de resultados")
            visualizer = OccupancyVisualizer(self.config.visualization)
            
            # Crear overlay con ocupaciÃ³n USANDO CUADRILÃTEROS REALES
            # Dibujar directamente sobre imagen original
            overlay = original.copy()
            
            for i, (shelf, occ_pct) in enumerate(zip(shelves, occupancy_percentages)):
                if hasattr(shelf, 'get_corners'):
                    # Dibujar cuadrilÃ¡tero con color segÃºn ocupaciÃ³n
                    corners = shelf.get_corners().astype(np.int32)
                    
                    # Color segÃºn ocupaciÃ³n: rojo (vacÃ­o) -> amarillo -> verde (lleno)
                    if occ_pct < 30:
                        color = (0, 0, 255)  # Rojo - bajo
                    elif occ_pct < 70:
                        color = (0, 255, 255)  # Amarillo - medio
                    else:
                        color = (0, 255, 0)  # Verde - alto
                    
                    # Dibujar polÃ­gono con transparencia
                    overlay_temp = overlay.copy()
                    cv2.fillPoly(overlay_temp, [corners], color)
                    cv2.addWeighted(overlay_temp, 0.3, overlay, 0.7, 0, overlay)
                    
                    # Dibujar borde del cuadrilÃ¡tero
                    cv2.polylines(overlay, [corners], True, color, 4)
                    
                    # Texto con ocupaciÃ³n en el centro
                    center = shelf.center
                    text = f"{occ_pct:.1f}%"
                    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)
                    
                    # Fondo negro para el texto
                    cv2.rectangle(overlay, 
                                (int(center[0]) - text_width//2 - 10, int(center[1]) - text_height//2 - 10),
                                (int(center[0]) + text_width//2 + 10, int(center[1]) + text_height//2 + 10),
                                (0, 0, 0), -1)
                    
                    cv2.putText(overlay, text, (int(center[0]) - text_width//2, int(center[1]) + text_height//2),
                               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
                else:
                    # Fallback para BoundingBox
                    if occ_pct < 30:
                        color = (0, 0, 255)
                    elif occ_pct < 70:
                        color = (0, 255, 255)
                    else:
                        color = (0, 255, 0)
                    cv2.rectangle(overlay, (shelf.x1, shelf.y1), (shelf.x2, shelf.y2), color, 4)
            
            self.steps['6_occupancy'] = overlay
            avg_occ = np.mean(occupancy_percentages)
            self.step_info['6_occupancy'] = f"OcupaciÃ³n Final\nPromedio: {avg_occ:.1f}%"
            logger.info(f"   âœ“ Overlay de ocupaciÃ³n creado")
            logger.info(f"   âœ“ OcupaciÃ³n promedio: {avg_occ:.1f}%\n")
            
            # Guardar metadatos
            self.metadata = {
                'image_path': str(image_path),
                'num_shelves': len(shelves),
                'occupancy_percentages': occupancy_percentages,
                'average_occupancy': float(avg_occ),
                'stats': stats_list,
                'dominant_angle_h': float(dominant_angle_h),
                'dominant_angle_v': float(dominant_angle_v),
                'uses_quadrilaterals': hasattr(shelves[0], 'get_corners') if shelves else False
            }
            
            logger.success("âœ… Pipeline completado exitosamente\n")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error en el pipeline: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def save_individual_steps(self, output_dir: Path, image_name: str):
        """
        Guarda cada paso como imagen individual.
        
        Args:
            output_dir: Directorio de salida
            image_name: Nombre base de la imagen
        """
        output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("ðŸ’¾ Guardando pasos individuales...")
        
        for step_name, step_image in self.steps.items():
            output_path = output_dir / f"{image_name}_{step_name}.jpg"
            save_image(step_image, output_path)
            logger.info(f"   âœ“ {output_path.name}")
        
        logger.info(f"\nðŸ“ Pasos guardados en: {output_dir}\n")
    
    def create_concatenated_view(
        self,
        output_path: Path,
        title: str = "Pipeline de AnÃ¡lisis de OcupaciÃ³n de Anaqueles"
    ):
        """
        Crea una visualizaciÃ³n concatenada con todos los pasos.
        
        Args:
            output_path: Ruta donde guardar la imagen concatenada
            title: TÃ­tulo de la visualizaciÃ³n
        """
        logger.info("ðŸŽ¨ Creando visualizaciÃ³n concatenada...")
        
        # Configurar figura
        n_steps = len(self.steps)
        cols = 4
        rows = (n_steps + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=(20, rows * 5))
        fig.suptitle(title, fontsize=20, fontweight='bold', y=0.995)
        
        # Aplanar axes para fÃ¡cil indexaciÃ³n
        if rows == 1:
            axes = axes.reshape(1, -1)
        axes_flat = axes.flatten()
        
        # Plotear cada paso
        for idx, (step_name, step_image) in enumerate(sorted(self.steps.items())):
            ax = axes_flat[idx]
            
            # Convertir BGR a RGB para matplotlib
            if len(step_image.shape) == 3:
                display_image = cv2.cvtColor(step_image, cv2.COLOR_BGR2RGB)
            else:
                display_image = step_image
            
            ax.imshow(display_image)
            ax.set_title(
                self.step_info.get(step_name, step_name),
                fontsize=12,
                fontweight='bold',
                pad=10
            )
            ax.axis('off')
        
        # Ocultar axes sobrantes
        for idx in range(n_steps, len(axes_flat)):
            axes_flat[idx].axis('off')
        
        # AÃ±adir informaciÃ³n de mÃ©tricas
        if hasattr(self, 'metadata'):
            info_text = f"Imagen: {Path(self.metadata['image_path']).name}\n"
            info_text += f"Anaqueles: {self.metadata['num_shelves']}\n"
            info_text += f"OcupaciÃ³n promedio: {self.metadata['average_occupancy']:.1f}%"
            
            fig.text(
                0.02, 0.02, info_text,
                fontsize=11,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
                verticalalignment='bottom'
            )
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close(fig)
        
        logger.success(f"âœ… VisualizaciÃ³n concatenada guardada: {output_path}\n")
    
    def generate_report(self, output_path: Path):
        """
        Genera un reporte en texto con las mÃ©tricas.
        
        Args:
            output_path: Ruta del archivo de reporte
        """
        if not hasattr(self, 'metadata'):
            logger.warning("No hay metadatos para generar reporte")
            return
        
        logger.info("ðŸ“ Generando reporte...")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("REPORTE DE ANÃLISIS DE OCUPACIÃ“N DE ANAQUELES\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"Imagen analizada: {Path(self.metadata['image_path']).name}\n")
            f.write(f"NÃºmero de anaqueles detectados: {self.metadata['num_shelves']}\n")
            f.write(f"OcupaciÃ³n promedio: {self.metadata['average_occupancy']:.2f}%\n\n")
            
            f.write("-" * 80 + "\n")
            f.write("MÃ‰TRICAS POR ANAQUEL\n")
            f.write("-" * 80 + "\n\n")
            
            for i, (occ_pct, stats) in enumerate(zip(
                self.metadata['occupancy_percentages'],
                self.metadata['stats']
            )):
                f.write(f"Anaquel {i+1}:\n")
                f.write(f"  - OcupaciÃ³n: {occ_pct:.2f}%\n")
                f.write(f"  - Celdas ocupadas: {stats['occupied_cells']}/{stats['total_cells']}\n")
                f.write(f"  - OcupaciÃ³n mÃ­n/mÃ¡x: {stats['min_occupancy']:.3f} / {stats['max_occupancy']:.3f}\n")
                f.write(f"  - DesviaciÃ³n estÃ¡ndar: {stats['std_occupancy']:.3f}\n")
                f.write("\n")
            
            f.write("=" * 80 + "\n")
        
        logger.success(f"âœ… Reporte guardado: {output_path}\n")


def main():
    """FunciÃ³n principal."""
    parser = argparse.ArgumentParser(
        description="Visualiza el pipeline completo de anÃ¡lisis de ocupaciÃ³n de anaqueles"
    )
    parser.add_argument(
        "--image",
        type=str,
        default=None,
        help="Ruta a la imagen a procesar. Si no se especifica, usa la primera disponible."
    )
    parser.add_argument(
        "--config",
        type=str,
        default="config/config.yaml",
        help="Ruta al archivo de configuraciÃ³n"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="data/results/pipeline_visualization",
        help="Directorio de salida para resultados"
    )
    
    args = parser.parse_args()
    
    # Configurar logging
    logger.remove()
    logger.add(sys.stderr, level="INFO")
    
    # Determinar imagen a procesar
    if args.image:
        image_path = Path(args.image)
        if not image_path.exists():
            logger.error(f"Imagen no encontrada: {image_path}")
            return 1
    else:
        # Buscar primera imagen disponible
        sample_dir = Path("data/raw/sample")
        image_files = list(sample_dir.glob("*.jpg")) + list(sample_dir.glob("*.png"))
        
        if not image_files:
            logger.error("No se encontraron imÃ¡genes en data/raw/sample/")
            return 1
        
        image_path = image_files[0]
        logger.info(f"Usando imagen: {image_path.name}\n")
    
    # Crear visualizador
    visualizer = PipelineVisualizer(args.config)
    
    # Procesar imagen
    success = visualizer.process_image(image_path)
    
    if not success:
        return 1
    
    # Crear directorio de salida
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    image_name = image_path.stem
    
    # Guardar pasos individuales
    steps_dir = output_dir / "individual_steps"
    visualizer.save_individual_steps(steps_dir, image_name)
    
    # Crear visualizaciÃ³n concatenada
    concat_path = output_dir / f"{image_name}_pipeline_complete.png"
    visualizer.create_concatenated_view(concat_path)
    
    # Generar reporte
    report_path = output_dir / f"{image_name}_report.txt"
    visualizer.generate_report(report_path)
    
    logger.info("=" * 80)
    logger.info("ðŸŽ‰ PROCESO COMPLETADO")
    logger.info("=" * 80)
    logger.info(f"\nðŸ“ Resultados guardados en: {output_dir}")
    logger.info(f"   - VisualizaciÃ³n completa: {concat_path.name}")
    logger.info(f"   - Pasos individuales: {steps_dir}/")
    logger.info(f"   - Reporte de mÃ©tricas: {report_path.name}\n")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
